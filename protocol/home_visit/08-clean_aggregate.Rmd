---
title: "Clean merged aggregate for sharing"
subtitle: "Version `r Sys.time()`"
author: Rick Gilmore
output: 
  html_document:
    code_folding: show
    self_contained: yes
    toc: yes
    toc_depth: 3
    toc_float: yes
params:
  project_root_dir: '..'
  release_version: 'release_1.0'
  in_fn: 'PLAY_non_mbcdi_all_databrary.csv'
  out_fn: 'PLAY_release_1.0_non_MBCDI_data.csv'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Purpose

This document imports a file that contains the merged and aggregated PLAY data, does additional cleaning on the file,  saves the aggregated file to a new `../aggregate` directory. 
To render, run `rmarkdown::render("08-clean_aggregate.Rmd")`.

# Setup

We load required libraries.

```{r}
library(tidyverse)
```

## Generate and check file paths

```{r}
csv_input_dir <- file.path(params$project_root_dir, 'data/csv', params$release_version, 'aggregate')
if (!dir.exists(csv_input_dir)) {
  stop('Directory not found: `', csv_input_dir, '`')
}

csv_save_dir <- file.path(params$project_root_dir, 'data/csv', params$release_version, 'aggregate')
if (!dir.exists(csv_save_dir)) {
  stop('Directory not found: `', csv_save_dir, '`')
  
}

in_file <- file.path(csv_input_dir, params$in_fn)
if (!file.exists(in_file)) {
  stop('File not found: `', in_file, '`')
}
```

# File processing

## Import data file

```{r import}
play <-
  read_csv(in_file,
           show_col_types = FALSE)
```

## Generate list of fields to delete

```{r}
site_sub_ids <- str_detect(names(play), 'site|subject_number')
notes_instructions_calc <- str_detect(names(play), 'note|instructions|calc')
start_end <- str_detect(names(play), 'start|end')
other_dates <- str_detect(names(play), 'date')
acknowledge <- str_detect(names(play), 'acknowledge')
version <- str_detect(names(play), 'version')
databrary_hooks <- str_detect(names(play), 'session|url|participant.ID|vol_id')
state <- str_detect(names(play), 'state')

remove_these <- site_sub_ids |
  notes_instructions_calc | 
  start_end | 
  other_dates | 
  acknowledge | 
  version | 
  databrary_hooks | 
  state
remove_cols <- (1:length(names(play)))[remove_these]

play_clean_1 <- play %>%
  dplyr::select(., -all_of(remove_cols))
```

## Clean-up Databrary field names

```{r}
# play_clean_2 <- play_clean_1 %>%
#   dplyr::rename(., child_race = participant_race,
#                 child_ethnicity = participant_ethnicity,
#                 child_disability = participant_disability,
#                 child_language = participant_language,
#                 exclusion_reason = exclusion_reason,
#                 qa_group = group_name,
#                 setting = context_setting,
#                 country = context_country,
#                 context_language = context_language)

play_clean_2 <- play_clean_1 %>%
  dplyr::rename(., child_race = participant_race,
                child_ethnicity = participant_ethnicity,
                child_disability = participant_disability,
                child_language = participant_language,
                exclusion_reason = exclusion_reason,
                qa_group = group_name,
                setting = context_setting,
                country = context_country)
```

## Remove duplicates

```{r}
play_clean_2 <- play_clean_2 %>%
  dplyr::distinct(.)
```

## Export

```{r}
if (dir.exists(csv_save_dir)) {
  write_csv(play_clean_2, file.path(csv_save_dir, params$out_fn))
} else {
  warning('Directory not found: `', csv_save_dir, '`')
  warning('File not saved.')
}
```

## Import data dictionary file

```{r}
dd <- read_csv(file.path(params$project_root_dir, "data_dict/release_1.0_non_mbcdi_data_dictionary.csv"), show_col_types = FALSE)
```

### Flag comparable rows that were removed for data file

```{r}
personally_identifying <- str_detect(dd$long_name, 'name') |
  str_detect(dd$long_name, 'address') |
  str_detect(dd$long_name, 'city') |
  str_detect(dd$long_name, 'phone') |
  str_detect(dd$long_name, 'email') |
  str_detect(dd$long_name, 'birthdate') |
  str_detect(dd$long_name, 'first[12]?') |
  str_detect(dd$long_name, 'last[12]?') |
  str_detect(dd$long_name, 'city') |
  str_detect(dd$long_name, 'year[12]?') |
  str_detect(dd$long_name, 'month[12]?') |
  str_detect(dd$long_name, '/day[12]?$') |
  str_detect(dd$long_name, 'session|url|participant.ID|vol_id') |
  str_detect(dd$long_name, 'site|subject_number')

admin_related <- str_detect(dd$long_name, 'note|instructions|calc') |
  str_detect(dd$long_name, 'start|end') |
  str_detect(dd$long_name, 'date') |
  str_detect(dd$long_name, 'acknowledge') |
  str_detect(dd$long_name, 'version')

dd$omitted_admin_related <- admin_related
dd$omitted_identifying <- personally_identifying
dd$shared <- !dd$omitted_admin_related & !dd$omitted_identifying
```

## Generate question group labels

```{r}
div_labor <- str_detect(dd$long_name, 'division_labor')
pets <- str_detect(dd$long_name, 'pets')
media_use <- str_detect(dd$long_name, 'mediause')
locomotor_milestones <-
  str_detect(dd$long_name, 'locomotor_milestone')
rothbart <- str_detect(dd$long_name, 'rothbart')
health <- str_detect(dd$long_name, 'group_health')
typical_day <- str_detect(dd$long_name, 'typical_day')

dd_tagged <- dd %>%
  dplyr::mutate(., question_group = ifelse(div_labor, 'div_labor',
                                           ifelse(
                                             pets, 'pets',
                                             ifelse(
                                               media_use,
                                               'media_use',
                                               ifelse(
                                                 locomotor_milestones,
                                                 'loco_milestones',
                                                 ifelse(rothbart,
                                                        'rothbart',
                                                        ifelse(
                                                          health, 'health', ifelse(typical_day, 'typical_day', 'other')
                                                        ))
                                               )
                                             )
                                           )))
dd_clean <- dd_tagged %>%
  dplyr::select(
    .,
    question,
    question_group,
    short_name,
    long_name,
    shared,
    omitted_admin_related,
    omitted_identifying
  )

write_csv(dd_clean,
          file.path(params$project_root_dir, 'data_dict/release_1.0_non_mbcdi_data_dictionary_clean.csv'))
```

