---
title: "PLAY Project: Surveys"
author: "Rick Gilmore"
date: "`r Sys.Date()`"
bibliography: ['include/bib/book.bib', 'include/bib/packages.bib']
css: include/css/styles.css
description: "Protocol for processing PLAY Project survey data"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "include/img/")
library(tidyverse)
```

# About {-}

```{r, echo=FALSE, out.width="75%", fig.link='https://play-project.org'}
knitr::include_graphics("include/img/PLAY-logo.png")
```

## Purpose {-}

PLAY project researchers use [KoBoToolbox](https://www.kobotoolbox.org/) to collect data from participant families.
Data from all sessions at all PLAY data collection sites are pushed to a common set of files on the KoBoToolbox server.

This document describes the process of i) downloading, ii) parsing, iii) cleaning, and iv) exporting these files into forms more suitable for data analysis.

For details about the PLAY Project data collection protocol, see <https://PLAY-behaviorome.github.io/protocol/>.

## Overview of data sets {-}

There are three sets of data collected using KoBoToolbox.
One set is collected during the recruiting and screening calls for the study.
The second set is collected during the home visit.
The third set consists of notes generated by the experimenter after the visit.

### Data access and processing {-}

All data are downloaded and manipulated locally but are **not** synched to GitHub.
This is accomplished by adding `data` to [`.gitignore`](.gitignore).

There are separate processes for detecting and deleting personal identifiers from specific data files and exporting 'cleaned' versions that may be shared on Databrary.

### Home visit data {-}

There are three (3) age groups (12-, 18-, and 24-month-olds) and four (4) different language environment groups (English-only, Spanish-only, Bilingual-English-dominant, Bilingual-Spanish-dominant).
Since the language of the questions and some of the specific questions vary by age group and by language environment group, there multiple KoBoToolbox survey form files that must be processed.

<!--chapter:end:index.Rmd-->

# (PART\*) Tools and Processes {-} 

<!--chapter:end:00-tools.Rmd-->

# Setup {-}

This section describes the setup procedure.

## Authentication {-}

The data are stored in an account on <https://kf.kobotoolbox.org>. 
The login credentials for that account are shared among the PLAY Project staff. 
To access the site's API programmatically, an API key was downloaded and added to the local `~/.Renviron` file.

<!-- https://bookdown.org/yihui/bookdown/html.html#callout-blocks -->
<!--Available blocks are: .rmdnote, .rmdcaution, .rmdimportant, .rmdtip, and .rmdwarning -->
::: {.rmdimportant}

The KoBoToolBox API key is **not** synched to GitHub.

:::


## Set-up {-}

To test whether the local system has the API key installed, we run the command `Sys.getenv("KOBO_API_KEY")`. 

### Check KoBo API Key {-}

```{r check-api-key}
kb_api <- Sys.getenv("KOBO_API_KEY")
if ((length(kb_api) != 1) || (!is.character(kb_api))) {
  stop("'KOBO_API_KEY' not installed in .Renviron")
} else {
  message("'KOBO_API_KEY' installed.")
}
```

### Check Databrary credentials {-}

The `databraryr` package handles authenticating to Databrary.
For scripting access to Databrary that require authentication, it is useful to store the user's Databrary login (email) in `.Renviron` using the R command `Sys.setenv(DATABRARY_LOGIN = "<email@provider.com>")` where you substitute your Databrary login (email) for `<email@provider.com>`.
When this has been accomplished the following code can be run to check the status of the saved variable.

```{r}
db_logon <- Sys.getenv("DATABRARY_LOGIN")
if ((length(db_logon) != 1) || (!is.character(db_logon)) || (db_logon == "")) {
  stop("'DATABRARY_LOGIN' not installed in .Renviron")
} else {
  message("'DATABRARY_LOGIN' installed.")
}
```

### Install dependencies {-}

We now use the [`renv`](https://cran.r-project.org/web/packages/renv/index.html) package to manage package dependencies.

### Load/source helper functions {-}

Most of the work is contained in `R/functions.R`.
This is sourced when we run `tar_make()` from the `{targets}` package.

::: {.rmdimportant}
We run `targets::tar_make()` manually for the time being.

None of the outputs are synced to GitHub.
:::

## Approach

To make the workflow more robust and reproducible, much of the work is embedded in functions and extensive use is made of the [`{targets}`](https://cran.r-project.org/web/packages/targets/) package. 
This document describes the workflow, but none of these code chunks are executed.

We leave execution to the `targets::tar_make()` function which updates components as needed.

:::{.rmdnote}
I am currently working on implementing most of the functions using the `box` package. This allows better isolation of dependencies within different components of the workflow.

The box-related functions are in a new `play/` directory, and the R source files are divided into categories.
The functions related to processing the screening/demographic data are in `play/screen.R`.

They will be loaded into the workspace via `box::use(play/screen)` or for modules within `play/` via `box::use(./screen)`.
:::

<!--chapter:end:01-setup.Rmd-->

# (PART\*) Data Wrangling {-} 

<!--chapter:end:10-wrangling.Rmd-->

# Screening call {-}

## Collection protocol {-}

Details about the data collection [protocol for participant screening and recruiting](https://www.play-project.org/collection.html#Participant_Recruitment) can be found on the [PLAY Project website](https://play-project.org).

## Retrieve from KoBoToolbox (KBT) {-}

We make use of the `targets` package for downloading data files from KoBoToolbox
and for saving local XLSX and CSV copies.
This allows us to download and process those files on a regular basis.

### Setup {-}

Load functions needed to download KBT screening/demographic questionnaire files.

```{r}
fl <- list.files(file.path(here::here(), "R"), "^kobo_|^file_", full.names = TRUE)
purrr::walk(fl, source)
```

### Download {-}

We have two targets specified in `_targets.R` that handle the regular downloading of screening data files.

First, we generate a data frame of KoBoToolbox forms that contain the screening ("Demographic") data.
Here is the target for that process:

```
# Not evaluated
  tar_target(
    kb_screen_df,
    kobo_list_data_filtered("[Dd]emographic"),
    cue = tarchetypes::tar_cue_age(
      name = kb_screen,
      age = as.difftime(update_interval, units = update_interval_units)
    )
  ),
```

Then we download and save the raw XLSX files to `../data/xlsx/screening` using `kobo_retrieve_save_many_xlsx(kb_screen_df, save_dir = "../data/xlsx/screening")`.
Finally, we convert the XLSX files to CSVs via `file_load_xlsx_save_many_csv("../data/xlsx/screening", "../data/csv/screening", "Demographic")`.
The latter two steps are handled by the wrapper function `screen_download_convert(kb_screen_df, "data/xlsx/screening", "data/csv/screening")`.
Here is the accompanying target:

```
# Download screening/demographic survey
  tar_target(
    screen_download,
    screen_download_convert(kb_screen_df, "data/xlsx/screening", "data/csv/screening"),
    cue = tarchetypes::tar_cue_age(
      name = screen_df,
      age = as.difftime(update_interval, units = update_interval_units)
    )
  ),
```

## Clean {-}

As of 2023-09-22, the cleaning and merging process for the screening/demographic data is handled here, in this document, not as a target.

### Setup {-}

A set of cleaning functions have the `screen_` prefix.

```{r}
purrr::walk(list.files(file.path(here::here(), "R"), 
                    "^screen_", full.names = TRUE), source)
```

There are three CSV files to clean:

```{r}
(fn <- list.files("../data/csv/screening", "[Dd]emographic", full.names = TRUE))
```

We clean them separately, as needed, then merge them.

### Clean variable names {-}

```{r read-screening-csvs}
df1 <-
  readr::read_csv(fn[1],
                  col_types = readr::cols(.default = 'c'),
                  show_col_types = FALSE)
df2 <-
  readr::read_csv(fn[2],
                  col_types = readr::cols(.default = 'c'),
                  show_col_types = FALSE)
df3 <-
  readr::read_csv(fn[3],
                  col_types = readr::cols(.default = 'c'),
                  show_col_types = FALSE)
```

```{r}
head(names(df1), 15)
```

```{r}
head(names(df2), 15)
```

```{r}
head(names(df3), 15)
```

There are a separate set of variable-by-variable cleaning functions in `R/screen_clean_utils.R`.

We remove the unneeded 'play_demo_*' and 'play_phone_questionnaire_' variable headers using `screen_remove_variable_headers()`.

We remove fields that contain administrative metadata with `screen_remove_metadata_fields()`.

We remove fields used only by staff in uploading data to Databrary using `screen_remove_databrary_fields()`.

We have name and address information in the screening data (e.g., '..parent_phone', '..parent_email', etc.) 

::: {.rmdnote}

In a future workflow, we will add Census FIPS IDs for the State and Country 
**before** removing the address information.

The Census queries stopped working around 2023-06-16.

For now, we remove identifiers without querying the Census.

:::

We remove identifiable information using `screen_remove_identifiers()`.

Then, we use `dplyr::full_join()` to combine the set of individually 
cleaned data files.
The `screen_clean_raw_csv()` function combines the previous `screen_remove*` functions.
The `screen_clean_raw_join()` function cleans each CSV then joins them.

```{r clean-screening-join}
(scr_df <- screen_clean_raw_join())
```

### Clean individual fields {-}

Now, we can proceed to clean-up the merged data frame.
The sequence of functions called below cleans 'construct-specific' variables
as indicated by the function names.

```{r show-screening-field-cleaning, eval=FALSE}
scr_df <- scr_df |> 
    screen_clean_child_info() |>
    screen_clean_lang_info() |>
    screen_clean_mom_info() |>
    screen_clean_biodad_father_info() |>
    screen_clean_childcare_info() |>
    screen_clean_family_structure() |>
    screen_clean_play_id() |>
    screen_remove_selected_cols() |>
    screen_select_reorder_cols()
```

For convenience, we package this sequence in its own function, `screen_clean_fields()`.

::: {.rmdnote}

Note that all of the variables are considered character strings. The `tidyverse`
suite does a great job of guessing what variables are what, but sometimes it
guesses wrongly. So, in preliminary stages, it has proved easier to make everything
a character string.

:::

```{r clean-merged-screen-fields}
scr_df <- screen_clean_fields(scr_df)
str(scr_df)
```

There is more work to do, but we have a version worth exporting.

## Merge {-}

Let's add the Databrary volume ID info.

```{r add-db-vol-id}
scr_df <- scr_df |>
  screen_add_db_vol_id()
```

Then filter out rows that do not have valid volume IDs.

```{r filter-invalid-db-vol-ids}
valid_db_vol <- !is.na(scr_df$vol_id)

scr_df <- scr_df[valid_db_vol,]
```

There are $n=$ `r sum(valid_db_vol)` valid Databrary volume IDs out of a total of $n=$ `r length(valid_db_vol)` screening records.

Next, we add a `play_status` field based on the `group-name` field from Databrary.
We use `group-name` for indicating "Gold", "Silver", or "Not run."

Two targets in `_targets.R` are relevant for this operation:

```
  tar_target(
    play_vols_df,
    readr::read_csv("data/csv/_meta/play_site_vols.csv",
                    show_col_types = FALSE)
  ),
  tar_target(
    databrary_session_csvs,
    purrr::map(play_vols_df$site_id, databrary_get_save_session_csv),
    cue = tarchetypes::tar_cue_age(
      name = databrary_session_csvs,
      age = as.difftime(update_interval, units = update_interval_units)
    )
  )

```

These targets generate site-specific CSVs in `data/csv/site_sessions` based on the database of PLAY sites contained in `data/csv/_meta/play_site_vols.csv`.
We load these CSVs into a single data frame.

### Load site session data

```{r add-db-status}
session_fns <-
  list.files("../data/csv/site_sessions", "\\.csv$", full.names = TRUE)

df_sessions <-
  purrr::map(
    session_fns,
    readr::read_csv,
    col_types = readr::cols(.default = 'c'),
    show_col_types = FALSE
  ) |>
  purrr::list_rbind()
```

The `group_name` variable contains status information about the sessions.

```{r}
xtabs(~ group_name, data=df_sessions)
```

We note that there are three different versions of no visit: "No visit", "No_visit", and "No_Visit". 
In addition, there are $n=$ `r sum(is.na(df_sessions$group_name))` sessions with NA in the `group_name`.
These could be sessions that are still in QA or which are scheduled, or there could be some other anomaly.
Here, we want to select only those sessions that occurred and which have passed QA--those sessions for which `group_name` is either 'PLAY_Gold' or 'PLAY_Silver'.

```{r}
df_sessions <- df_sessions |>
  dplyr::filter(stringr::str_detect(group_name, "PLAY_"))
```

### Sharing by session status

Here is information about the sharing status.

```{r}
xtabs(~ group_name + session_release, df_sessions)
```
There was one session marked `PRIVATE`.

```{r}
df_sessions |>
  dplyr::filter(session_release == "PRIVATE") |>
  dplyr::select(vol_id, session_id, session_name, group_name)
```
Now, we join the screening data with the Databrary session data.

```{r}
screen_datab_df <- dplyr::left_join(df_sessions, scr_df, by = c('vol_id', 'participant_ID'))
```

Let's do some additional cleaning of redundant column names, e.g., exclusion.

```{r}
screen_datab_df <- screen_datab_df |>
  tidyr::unite(exclusion_reason, c("exclusion1_reason", "exclusion2_reason", "exclusion_reason")) |>
  dplyr::mutate(exclusion_reason = stringr::str_remove_all(exclusion_reason, "NA|_"))
```

## Export cleaned file {-}

We date-stamp the exported file so we can monitor progress as this workflow develops.

```{r export-screen}
sfn <- paste0("PLAY-screening-datab-", Sys.Date(), ".csv")
readr::write_csv(screen_datab_df, file.path(here::here(), "data/csv/screening/agg/", sfn))
```

We also save a copy with "latest".

```{r export-latest}
sfn <- "PLAY-screening-datab-latest.csv"
readr::write_csv(screen_datab_df, file.path(here::here(), "data/csv/screening/agg/", sfn))
```

<!--chapter:end:12-screening.Rmd-->

# Home visit {-}

## Protocol {-}

Details about the data collection protocol for the home visit can be found on the [PLAY Project website](https://www.play-project.org/collection.html#Home_Visit).

## Overview {-}

The notes below summarize the steps needed to process the home visit survey data.
Most of the R chunks are **not** run, however, since we have moved the work into a [`\{targets\}`](https://docs.ropensci.org/targets/)-based workflow.

## Download data {-}

Data files for each of the language by age-group conditions are stored on KoBoToolbox (KBT).

Store all of the data files on KBT in `kb_df`.

```
tar_target(kb_df, list_kobo_data()),
```

```{r home-visit-list-forms, eval=FALSE}
library(targets)
targets::tar_load(kb_df, store="../_targets")
kb_df
```

List data forms specific to the home visit by filtering the files with names that contain "Home".

```
tar_target(kb_home, dplyr::filter(kb_df, stringr::str_detect(title, "Home")))
```

```{r home-visit}
targets::tar_load(kb_home, store="../_targets")
kb_home
```

### Save selected raw files to local directory {-}

Prepare to retrieve all home visit files.

```{r}
n_files <- dim(kb_home)[1]
```

There are $n=$ `r dim(kb_home)[1]` home visit data files.

```
tar_target(
  home_visit_downloads,
  retrieve_kobo_xlsx(kb_home, 
    "data/xlsx/home_visit/raw"),
  cue = tarchetypes::tar_cue_age(
    name = home_visit_downloads,
    age = as.difftime(update_interval, 
      units = update_interval_units)
  )
)
```

### Normalize file names {-}

Some of the form names are inconsistent, so we normalize them to fit the following pattern:

`<form_id>_PLAY_HomeQuestionnaires_<age_group>_<lang_group>.xlsx`

```
tar_target(
  home_visit_renamed,
  rename_home_xlsx(home_visit_downloads,
                     "data/xlsx/home_visit/std_name"),
  cue = tarchetypes::tar_cue_age(
    name = home_visit_renamed,
    age = as.difftime(update_interval, 
      units = update_interval_units)
  )
)
```

### Save xlsx as csv {-}

```
tar_target(
  home_visit_xlsx_to_csv,
  load_xlsx_save_many_csvs_2(home_visit_renamed, 
    "data/csv/home_visit/raw")
)
```

### Split MB-CDI from other questions {-}

Next we import a CSV for a given form year, age group, and language group, and create two new CSV files: one with the MB-CDI data and one with all of the other survey questions.

By default, the document presumes that we want to convert **all** of the CSV files

Extract the 'non-mbcdi' questions first and add 'non_mbcdi' to the filename.

```
tar_target(
  home_visit_non_mbcdi,
  split_non_mbcdi_csvs(home_visit_xlsx_to_csv,
                        "data/csv/home_visit/non_mbcdi")
)
```

Extracting the MB-CDI data has nearly the same function call, but the `these_questions` parameter is set to 'mbcdi'.

```
tar_target(
  home_visit_mbcdi,
  split_mbcdi_csvs(home_visit_xlsx_to_csv,
                    "data/csv/home_visit/mbcdi")
)
```

## Clean data {-}

### Remove identifiers {-}

The function `remove_identifiers()` in `R/kobo_export` detects the presence of names, addresses, phone numbers, email, and dates in the field names for an input file and removes these fields.
It also modifies the file name by appending `_deidentified`.

The `remove_identifiers()` function detects these fields
For clarity, we print it here.

```{r}
source("~/rrr/KoBoToolbox/R/_OLD/functions.R", echo = FALSE, print.eval = FALSE)
remove_identifiers
```

The **non-MBCDI file** contains the identifiers, so that is the target of this removal process.

::: {.rmdnote}
Note that we have added `data` to `.gitignore` in `protocol/`, the root directory for the HTML protocol, so *none* of the data files should be made available via git or GitHub. This also means that there is **no version control** being done on raw data files themselves.
:::

```
tar_target(
  home_visit_remove_identifiers,
  purrr::map_chr(
    home_visit_non_mbcdi,
    open_deidentify_save,
    csv_save_dir = "data/csv/home_visit/non_mbcdi/deid",
      these_questions = 'non_mbcdi'
  )
)
```

## Quality assurance (QA) reviews {-}

### MB-CDI files {-}

### Non-MB-CDI files {-}

Create a helper function to create a data set with summary information about the data files.

```{r define-qa-helper}
summarize_non_mbcdi_qs <- function(fn) {
  stopifnot(is.character(fn))
  
  if (!file.exists(fn)) {
    stop('File not found `', fn, '`')
  } else {
    df <- readr::read_csv(fn, show_col_types = FALSE)
    if (!is.data.frame(df)) {
      stop('Error reading data frame')
    } else {
      out_df <-
        tibble(
          file_name = basename(fn),
          n_rows = dim(df)[1],
          n_vars = dim(df)[2]
        )
      dplyr::arrange(out_df, file_name)
    }
  }
}
```

Select the de-identified CSVs to examine.

```{r generate-qa-report}
fl <-
  list.files(
    file.path("../data/csv/home_visit/non_mbcdi/deid"),
    '^[0-9]+_non_mbcdi_[12|18|24].*deidentified',
    full.names = TRUE
  )

PLAY_forms <- purrr::map_df(fl, summarize_non_mbcdi_qs)

PLAY_forms %>%
  knitr::kable(., format = 'html') %>%
  kableExtra::kable_classic()
```

The later forms (with higher form numbers--the leading integers in the file names) are the newer ones.
These generally have the largest number of entries and have similar numbers of columns--either 287 or 288.
Accordingly, we focus our cleaning efforts here first.

We start with the data files that have $n=288$ columns.

```{r}
df740623 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740623_non_mbcdi_12_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )

df740624 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740624_non_mbcdi_12_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740623) == names(df740624))
```

```{r}
df740625 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740625_non_mbcdi_12_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740623) == names(df740625))
```

```{r}
df740628 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740628_non_mbcdi_18_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740623) == names(df740628))
```

So, four of the most recent data files with $n=288$ columns can be aggregated without modification.

Let's turn to the more recent files with $n=287$ columns.

```{r}
df740626 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740626_non_mbcdi_18_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )

df740627 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740627_non_mbcdi_18_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740627))
```

Where does the misalignment arise?

```{r}
names(df740626) == names(df740627)
```

The misalignment arises somewhere near column 92.

```{r}
df740629 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740629_non_mbcdi_24_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740629))
```

So, `df740626` and `df740629` are aligned and can be merged.

```{r}
df740630 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740630_non_mbcdi_24_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740630))
names(df740626) == names(df740630)
```

These files also fall out of alignment near column 92.

```{r}
df740631 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740631_non_mbcdi_24_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740631))
names(df740626) == names(df740631)
```

And these files fall out of alignment near column 92.

Let's see if `df740627`, `df740630`, and `df740631` are aligned with one another.

```{r}
sum(names(df740627) == names(df740630))
sum(names(df740627) == names(df740631))
```

Yes, they are. So, these three can be merged. 
We do that first, then address the discrepancies between aggregates.

### 'Older' forms {-}

The "older" forms have varied numbers of columns.
We focus on thos with data (n_vars > 0)

```{r}
df307736 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/307736_non_mbcdi_18_english_deidentified.csv",
    show_col_types = FALSE
  )
df331453 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/331453_non_mbcdi_24_english_deidentified.csv",
    show_col_types = FALSE
  )
df331848 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/331848_non_mbcdi_12_english_deidentified.csv",
    show_col_types = FALSE
  )
df334099 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/334099_non_mbcdi_12_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )
df363349 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/363349_non_mbcdi_18_english_deidentified.csv",
    show_col_types = FALSE
  )
df363381 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/363381_non_mbcdi_24_english_deidentified.csv",
    show_col_types = FALSE
  )
df363431 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/363431_non_mbcdi_12_english_deidentified.csv",
    show_col_types = FALSE
  )
df408149 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/408149_non_mbcdi_24_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )
df411456 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/411456_non_mbcdi_12_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )
df411469 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/411469_non_mbcdi_12_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )
```

Let's look at the two forms that have the same number of columns, $n=274$, 307736 and 331453.

```{r}
names(df307736) == names(df331453)
length(names(df307736) == names(df331453)) == length(names(df307736))
```
So, these two are identical and could be merged.

```
tar_target(files_274_cols, stringr::str_detect(home_visit_remove_identifiers, "/(307736|331453)"))

tar_target(df_merge_274_cols, make_aggregate_data_file(home_visit_remove_identifiers[files_274_cols]))
```

How about the files with $n=267$ columns, 331848 and 334099?

```{r}
names(df331848) == names(df334099)
length(names(df331848) == names(df334099)) == length(names(df331848))
```

```{r}
names(df331848) |> head()
names(df334099) |> head()
```
There is an odd difference in the group label, `group_combinedquestionnaires` vs. `group_jo84c13`.

Let's try deleting the initial group labels and compare again.

```{r}
n1 <- names(df331848)
n2 <- names(df334099)

names(df331848) %>% stringr::str_remove("group_combinedquestionnaires/") |> head()
names(df334099) %>% stringr::str_remove("group_jo84c13/") |> head()
```
That looks promising.

```{r}
names(df331848) %>% stringr::str_remove("group_combinedquestionnaires/") -> n1
names(df334099) %>% stringr::str_remove("group_jo84c13/") -> n2
n1 == n2
```
```{r}
cbind(n1[8:15], n2[8:15])
```
`n2` or `df334099` has a `child_birth_date` field in position 9 that the other data frame does not have.

```{r}
n1 |> str_detect("child_birth_date") |> sum()
```

If we delete that variable, the data frames will no longer have the same number of columns.
Let's explore that anyway.

```{r}
n2_2 <- n2[-9]

n1 == n2_2
```

That helps a bit, but we diverge around column 29.

```{r}
cbind(n1[28:51], n2_2[28:51])
```

These question labels looks very similar.
There are just some minor changes in the variable names.
`n2_2` has an extra variable in column 40.

```{r}
n2_3 <- n2_2[-40]
```

Then, we can rename some of the columns in `n2_3` using corresponding names from `n1`.

```{r}
n2_3 |> stringr::str_replace("yes__in_the_bi", "birthhospital") |> stringr::str_replace("yes__after_goi", "afterhome") |> stringr::str_replace("don_t_know", "donotknow") -> n2_4

n1 == n2_4
```

```{r}
cbind(n1[39:51], n2_4[39:51])
```

`n1` has a `group_medicalprof` label from `allergies` through `gastrointestinal`; `n2_4` has `child_allergies_infections_ill` for the same questions.

```{r}
n2_4 |> stringr::str_replace("child_allergies_infections_ill", "group_medicalprof") -> n2_5
n1 == n2_5
```


```{r}
cbind(n1[49:60], n2_5[49:60])
```

It looks like these could be reconciled by deleting `prenatal_care` from `n1`.

```{r}
n1_2 <- n1[-50]
n1_2 == n2_5
```
```{r}
cbind(n1_2[64:75], n2_5[64:75])
```

It looks like the phq4 is *not* in `n2_5`.

Let's check.

```{r}
n2_5 |> stringr::str_detect("phq4") |> sum()
```

Yes, there are only two PHQ4-related questions in `df334099`.

```{r}
df334099 |> names() |> stringr::str_detect("phq4") |> sum()
```

This path of reconciliation does not appear fruitful.

## Make aggregate files {-}

### non-MB-CDI files with $n=288$ columns {-}

```
tar_target(files_288_cols, 
  stringr::str_detect(home_visit_remove_identifiers, 
                      "2[3458]_non_mbcdi.*_deidentified\\.csv")
)

tar_target(df_merge_288_cols,
    make_aggregate_data_file(
        home_visit_remove_identifiers[files_288_cols])
)
```

### non-MB-CDI files with $n=287$ columns {-}

```
tar_target(files_287_cols_1, 
  stringr::str_detect(home_visit_remove_identifiers, 
          "2[69]_non_mbcdi.*_deidentified\\.csv")),
tar_target(files_287_cols_2, 
  stringr::str_detect(home_visit_remove_identifiers, 
          "(740627|740630|740631)_non.*_deidentified\\.csv")),
tar_target(df_merge_287_cols_1,
  make_aggregate_data_file(
          home_visit_remove_identifiers[files_287_cols_1])),
tar_target(df_merge_287_cols_2,
  make_aggregate_data_file(
          home_visit_remove_identifiers[files_287_cols_2])),
```

### Examine groups with $n=287$ cols {-}

We focus on the starting column where the column names diverge, column 92.

```{r}
targets::tar_load(df_merge_287_cols_1, store="../_targets")
targets::tar_load(df_merge_287_cols_2, store="../_targets")
names(df_merge_287_cols_1)[92]
names(df_merge_287_cols_2)[92]
```

There is an erroneous `group_locomotor_milestones.` in the `df_merge_287_cols_2` column name.

A bit of sleuthing determines that this `group_locomotor_milestones.` label is characteristic of columns 92 to 273.

```{r}
names(df_merge_287_cols_2)[92:273] |> stringr::str_detect(pattern = "group_locomotor_milestones")
```

The following should fix this.

```{r}
old_names <- names(df_merge_287_cols_2)
new_names <- old_names
new_names[92:273] <-
  stringr::str_remove(new_names[92:273], "group_locomotor_milestones\\.")
names(df_merge_287_cols_2) <- new_names
```

```{r}
names(df_merge_287_cols_2) == names(df_merge_287_cols_1)
```

We have a second problem with columns from 114 to 210.

```{r}
rbind(names(df_merge_287_cols_1)[113:115], names(df_merge_287_cols_2)[113:115])
```

One of the problems has to do with column 114. There is a question ending `doctor_told_you` in `names(df_merge_287_cols_1)` but not in `names(df_merge_287_cols_2)`.

```{r}
names(df_merge_287_cols_1) |> stringr::str_detect(pattern = "doctor_told_you") |> sum()
names(df_merge_287_cols_2) |> stringr::str_detect(pattern = "doctor_told_you") |> sum()
```

Deleting this question would create additional misalignments and further problems.
We cannot proceed without further discussion with our team.

For now, let's generate an array with all of the remaining differences in column names.

```{r}
names_differ <- (names(df_merge_287_cols_2) != names(df_merge_287_cols_1))
sum(names_differ)
```

```{r}
rbind(names(df_merge_287_cols_1)[names_differ], names(df_merge_287_cols_2)[names_differ])
```

Visual inspection suggests that these are similar with the following deviations:

- As noted, `df_merge_287_cols_1` has a column ending `doctor_told_you` that is not present in `df_merge_287_cols_2`.
- `df_merge_287_cols_2` has a column ending `technology_use_scale` that is not present in the `df_merge_287_cols_1`
- There are a set of fields in `group_databrary` that do not align exactly. We will almost certainly delete these, so the misalignment is not a huge problem.

As an exploration, let's see if we can reconcile these by deleting the non-aligning columns.

```{r}
df1 <- df_merge_287_cols_1
df2 <- df_merge_287_cols_2

df1 <- df1 %>%
  dplyr::select(., -contains('doctor_told_you'))

df2 <- df2 %>%
  dplyr::select(., -contains('technology_use_scale'))

old_names <- names(df2)
new_names <- old_names
new_names[92:273] <- stringr::str_remove(new_names[92:273], "group_locomotor_milestones\\.")
names(df2) <- new_names

names(df1) == names(df2)
```

This looks promising.

```{r}
rbind(names(df1)[263], names(df2)[263])
```

This is easily fixed.

```{r}
names(df1)[263] <- names(df2)[263]
```

```{r}
rbind(names(df1)[273:275], names(df2)[273:275])
```

The last misalignments relate to Databrary fields.

```{r}
df1 <- df1 %>%
  dplyr::select(., -contains('group_databrary'))

df2 <- df2 %>%
  dplyr::select(., -contains('group_databrary'))

names(df1) == names(df2)
```

Success!

## Combining the two groups of datasets {-}

Now, let's go back to the data frame with 288 cols and see if we can bring these into alignment.

```{r}
targets::tar_load(df_merge_288_cols, store="../_targets")

df3 <- df_merge_288_cols

df3 <- df3 %>%
  dplyr::select(., -contains('group_databrary'))

c(dim(df1), dim(df2), dim(df3))

names(df1) == names(df3)
rbind(names(df1)[114:115], names(df3)[114:115])
```

Once again, there appears to be a problem with the 'doctor_told_you' field. We'll delete it to see if this fixes one of the problems.

```{r}
df3 <- df3 %>%
  dplyr::select(., -contains('doctor_told_you'))

names(df1) == names(df3)
```

We still have misalignments at column 210.

```{r}
rbind(names(df1)[210:213], names(df3)[210:213])
```

The 'technology_use_scale` exists in one but not the other.

```{r}
df3 <- df3 %>%
  dplyr::select(., -contains('technology_use_scale'))

rbind(dim(df1), dim(df3))

names(df1) == names(df3)
```

:::{.rmdimportant}
Future versions of the workflow will need to handle this more elegantly. 

Option 1: Fix the underlying forms.

Option 2: Add the 'missing' columns as NA in post-processing.
:::

For now, I'm going to create functions that align these data frames.
These are incorporated into `R/functions.R` so we do not source them again here.

```{r, eval=FALSE}
remove_technology_use_scale <- function(df) {
  dplyr::select(df, -contains('technology_use_scale'))
}

remove_doctor_told_you <- function(df) {
  dplyr::select(df, -contains('doctor_told_you'))
}

remove_databrary_fields <- function(df) {
  dplyr::select(df, -contains('group_databrary'))
}

reconcile_typicalday <- function(df) {
  names(df) <- stringr::str_replace_all(names(df), 'typicalday', 'typical_day')
  df
}

remove_permissive_locomotor_milestones_label <- function(df) {
  old_names <- names(df)
  new_names <- old_names
  contains_locomotor <-
    stringr::str_detect(new_names, pattern = "locomotor_milestones.*health|division|rothbart|mediause|pets|typical|acknowledge")
  new_names[contains_locomotor] <-
    stringr::str_remove(new_names[contains_locomotor], "group_locomotor_milestones\\.")
  names(df) <- new_names
  df
}

remove_X_meta_cols <- function(df) {
  dplyr::select(df, -contains("X_"), -contains("meta.instanceID"))
}

remove_redundant_group_labels <- function(df) {
  names(df) <- stringr::str_remove_all(names(df), 'group_homevisitquestionnaires\\.')
  names(df) <- stringr::str_remove_all(names(df), 'group_combinedquestionnaires\\.')
  df
}

clean_dfs <- function(df) {
  df %>%
    reconcile_typicalday() %>%
    remove_technology_use_scale() %>%
    remove_doctor_told_you() %>%
    remove_permissive_locomotor_milestones_label() %>%
    remove_databrary_fields() %>%
    remove_X_meta_cols() %>%
    remove_redundant_group_labels()
}
```

Let's test this workflow with the unmodified files.

```{r}
targets::tar_load(df_merge_287_cols_1, store="../_targets")
targets::tar_load(df_merge_287_cols_2, store="../_targets")
targets::tar_load(df_merge_288_cols, store="../_targets")

df1m <- clean_dfs(df_merge_287_cols_1)
dim(df1m)

df2m <- clean_dfs(df_merge_287_cols_2)
dim(df2m)

df3m <- clean_dfs(df_merge_288_cols)
dim(df3m)

(names(df1m) == names(df2m)) |> sum()
(names(df1m) == names(df3m)) |> sum()
```

### Merging files at last {-}

```{r, eval=FALSE}
df <- rbind(df1m, df2m, df3m)
```

::: {.rmdnote}
As of 2022-12-15, the above has now been incorporated into `R/functions.R` and into the `_targets.R` workflow.
:::

## Merge with Databrary info {-}

For each session (row) in the merged data frame, we pull data from the associated Databrary volume and session.
These data are merged with that drawn from KBT.

```
tar_target(
  home_visit_w_databrary_df,
  add_databrary_info_to_home_visit_df(home_visit_df)
)
```

The `add_databrary_info_to_home_visit()` function in `R/functions.R` does most of the work.

## Clean and prepare for export {-}

<!--chapter:end:13-home-visit.Rmd-->

# QA for merging {-}

## Purpose {-}

This page summarizes which screening/demographics data and which home visit data have anomalies or missing data.

## Screening/demographic data {-}

```{r}
screen_df <-
  readr::read_csv(
    file.path(
      here::here(),
      "data",
      "csv",
      "screening",
      "agg",
      "PLAY-screening-datab-latest.csv"
    ),
    col_types = readr::cols(.default = 'c'),
    show_col_types = FALSE
  )
```

The following rows have incomplete or missing `site_id` values:

```{r}
screen_df |>
  dplyr::filter(is.na(site_id) | is.null(site_id)) |>
  dplyr::select(site_id, vol_id, participant_ID, session_id, play_id, group_name) |>
  dplyr::arrange(vol_id, site_id, participant_ID) |>
  knitr::kable() |>
  kableExtra::kable_classic()
```

::: {.rmdnote}

Volume 1103 is OHIOS. Volume 1482 is CSUFL. Volume 954 is GEORG.
The missing values for `vol_id` indicate that there is a bug in the [cleaning code](screening-call.html).

**2023-10-20**

On closer investigation, the screening data do _not_ show an OHIOS session with `participant_ID` == '001'. There are three with '000' and two with '002'.

Similarly, for CSUFL, there is no '003' or '006'. We have home visit data for '006'.

Similarly, for GEORG, there is a '???', but no '001'.

:::

The following rows have incomplete or missing `participant_ID` values:

```{r}
screen_df |>
  dplyr::filter(is.na(participant_ID) | is.null(participant_ID)) |>
  dplyr::select(site_id, vol_id, participant_ID, session_id, play_id, group_name) |>
  dplyr::arrange(vol_id, site_id, participant_ID) |>
  knitr::kable() |>
  kableExtra::kable_classic()
```

The following rows have incomplete or missing `play_id` values:

```{r}
screen_df |>
  dplyr::filter(is.na(play_id) | is.null(play_id)) |>
  dplyr::select(site_id, vol_id, participant_ID, session_id, play_id, group_name) |>
  dplyr::arrange(vol_id, site_id, participant_ID) |>
  knitr::kable() |>
  kableExtra::kable_classic()
```

::: {.rmdnote}

There are duplicate entries for OHIOS 1103 56674 002.

We should add duplicate checking to the cleaning code.

:::

::: {.rmdnote}

There are `r stringr::str_detect(names(screen_df), "exclusion") |> sum()` variables with information about exclusion status:

```{r}
ex_dups <- stringr::str_detect(names(screen_df), "exclusion")
names(screen_df)[ex_dups]
```

These probably result from some bug in the `*_join` operation in the [cleaning process](screening-call.html#merge).
They should be merged.

:::

## Home visit data {-}

```{r}
targets::tar_load(home_visit_df, store=file.path(here::here(), "_targets"))
```

The `home_visit_df` data have some field names that are inconsistent with the screening/demographic data files.
We reconcile these differences first.

```{r}
home_df <- home_visit_df |>
    dplyr::rename("play_id" = "participant_id") |>
    dplyr::rename("participant_ID" = "subject_number")
```

Since the `home_visit_df` data have not yet been merged with Databrary information, the `vol_id` and `group_name` variables are not available.

The following rows have incomplete or missing `site_id` values:

```{r}
home_df |>
  dplyr::filter(is.na(site_id) | is.null(site_id)) |>
  dplyr::select(site_id, participant_ID, play_id) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable() |>
  kableExtra::kable_classic()
```

The following rows have incomplete or missing `participant_ID` values:

```{r}
home_df |>
  dplyr::filter(is.na(participant_ID) | is.null(participant_ID)) |>
  dplyr::select(site_id, participant_ID, play_id) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable() |>
  kableExtra::kable_classic()
```

The following rows have incomplete or missing `play_id` values:

```{r}
home_df |>
  dplyr::filter(is.na(play_id) | is.null(play_id)) |>
  dplyr::select(site_id, participant_ID, play_id) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable() |>
  kableExtra::kable_classic()
```

<!--chapter:end:14-merge-report.Rmd-->

# MB-CDI {-}

## Purpose {-}

This page documents the cleaning and merging procedures related to the MB-CDI data.
The home visit workflow strips these files into their own set of CSVs under `data/csv/home_visit/mbcdi`.

The aggregate (across language group and age) data files are saved under `data/csv/agg`.

## Preparation {-}

```{r}
source(file.path(here::here(), "R", "_OLD", "functions.R"))

purrr::walk(list.files(file.path(here::here(), "R"), "\\.R$", full.names = TRUE), source)
```

Let's investigate the number of files, records, and variables per file.

```{r}
mbcdi_fns <-
  list.files(file.path(here::here(), "data", "csv", "home_visit", "mbcdi"), "\\.csv$", full.names = TRUE)

length(mbcdi_fns)
```

```{r make_datafile_summary}
make_datafile_summary <- function(csv) {
  assertthat::is.string(csv)
  assertthat::is.readable(csv)
  
  df <-
    readr::read_csv(csv,
                    col_types = readr::cols(.default = 'c'),
                    show_col_types = FALSE)
  
  
  
  data.frame(fn = csv,
             age_group = extract_age_group_from_name(csv),
             lang_cond = form_language(csv),
             n_subs = dim(df)[1],
             n_vars = dim(df)[2])
}
```

```{r mbcdi-file-rpt}
mbcdi_file_dat <-
  purrr::map(mbcdi_fns, make_datafile_summary) |> purrr::list_rbind()

mbcdi_file_dat |>
  dplyr::arrange(age_group, lang_cond, n_subs) |>
  knitr::kable(format = 'html') |>
  kableExtra::kable_classic()
```

## 12-mo-old English speakers {-}

```{r}
eng_12_files <- mbcdi_file_dat |>
  dplyr::filter(age_group == '12', lang_cond == 'english', n_subs > 0)
```

```{r}
eng_12_combined_df <- purrr::map(eng_12_files$fn, mcdi_clean_12_csv) |>
  purrr::list_rbind()
```

```{r}
eng_12_fn <- file.path(here::here(), "data", "csv", "home_visit", "agg", "mcdi_english_12_combined.csv")
readr::write_csv(eng_12_combined_df, eng_12_fn)
```

There are $n=$ `r dim(eng_12_combined_df)[1]` participant records.

## 18-mo-old English speakers {-}

::: {.rmdnote}

This code should be wrapped in functions since many of the components duplicate one another.

:::

```{r}
eng_18_files <- mbcdi_file_dat |>
  dplyr::filter(age_group == '18', lang_cond == 'english', n_subs > 0)
```

```{r}
eng_18_combined_df <- purrr::map(eng_18_files$fn, mcdi_clean_18_24_csv) |>
  purrr::list_rbind()
```

```{r}
eng_18_fn <- file.path(here::here(), "data", "csv", "home_visit", "agg", "mcdi_english_18_combined.csv")
readr::write_csv(eng_18_combined_df, eng_18_fn)
```

There are $n=$ `r dim(eng_18_combined_df)[1]` participant records.

## 24-mo-old English speakers {-}

```{r}
eng_24_files <- mbcdi_file_dat |>
  dplyr::filter(age_group == '24', lang_cond == 'english', n_subs > 0)
```

```{r}
eng_24_combined_df <- purrr::map(eng_24_files$fn, mcdi_clean_18_24_csv) |>
  purrr::list_rbind()
```

```{r}
eng_24_fn <- file.path(here::here(), "data", "csv", "home_visit", "agg", "mcdi_english_24_combined.csv")
readr::write_csv(eng_24_combined_df, eng_24_fn)
```

There are $n=$ `r dim(eng_18_combined_df)[1]` participant records.

## Old code {-}

::: {.rmdnote}

The following code is deprecated as of 2023-10-25, and is _not_ run.

:::

For simplicity, we'll start with the youngest age group, and with the English speakers.
There are $n=3$ forms, with 4, 10, and 111 participants each, and 254, 253, and 257 variables.

```{r, eval=FALSE}
eng_12_files <- mbcdi_file_dat |>
  dplyr::filter(age_group == '12', lang_cond == 'english', n_subs > 0)
```

We'll examine the first one.

```{r, eval=FALSE}
eng_12_331 <- readr::read_csv(eng_12_files$fn[1],
                    col_types = readr::cols(.default = 'c'),
                    show_col_types = FALSE)

names(eng_12_331) |> head()
```

Let's try trimming the metadata labels.

```{r, eval=FALSE}
eng_12_331_trim_names <- 
  names(eng_12_331) |> basename()

eng_12_331_trim_names |> head()
```

That looks better.
Let's look at the second file.

```{r, eval=FALSE}
eng_12_363 <- readr::read_csv(eng_12_files$fn[2],
                    col_types = readr::cols(.default = 'c'),
                    show_col_types = FALSE)

names(eng_12_363) |> basename() |> head()
```

And the third one.

```{r, eval=FALSE}
eng_12_740625 <- readr::read_csv(eng_12_files$fn[3],
                    col_types = readr::cols(.default = 'c'),
                    show_col_types = FALSE)

names(eng_12_740625) |> basename() |> head()
```

Now, we'll create a function to clean the variable names.

```{r, eval=FALSE}
select_basename <- function(csv_fn) {
  assertthat::is.string(csv_fn)
  assertthat::is.readable(csv_fn)
  
  df <- readr::read_csv(csv_fn,
                    col_types = readr::cols(.default = 'c'),
                    show_col_types = FALSE)
  
  names(df) <- basename(names(df))
  df
}
```

```{r, eval=FALSE}
select_basename(eng_12_files$fn[3]) |> head()
```

Let's trim unneeded fields.
We'll write several helper functions to do this.

```{r, eval=FALSE}
trim_cdi_fields <- function(df) {
  df |>
    dplyr::select(-contains("note"),
                  -contains("instructions"),
                  -contains("comments"),
                  -contains("continue"),
                  -contains("vocab"),
                  -contains("mcdi"))
}

add_particip_index <- function(df) {
  df |> 
    dplyr::mutate(play_i = 1:dim(df)[1])
}

make_cdi_longer <- function(df) {
  n_vars <- dim(df)[2]
  df |>
    tidyr::pivot_longer(cols = 2:n_vars,
                        names_to = "word",
                        values_to = "understands_or_says") |>
    dplyr::filter(!is.na(understands_or_says)) |>
    dplyr::mutate(understands_or_says = stringr::str_replace(understands_or_says, "understands___", "says")) |>
    dplyr::mutate(
      understands_or_says = stringr::str_replace(understands_or_says, "understands_says", "says")) |>
    dplyr::mutate(word = stringr::str_replace(word, "mommy_001", "mommy")) |>
    dplyr::mutate(word = stringr::str_replace(word, "bath_001", "bath"))
}
```

Then we combine them into an omnibus function.

```{r, eval=FALSE}
clean_cdi <- function(csv_fn) {
  select_basename(csv_fn) |>
    trim_cdi_fields() |>
    dplyr::rename("play_id" = "participant_id") |>
    make_cdi_longer() |>
    add_particip_index()
}
```

Now, we can run `clean_cdi()` across all three files.

```{r, eval=FALSE}
eng_12 <- purrr::map(eng_12_files$fn, clean_cdi) |>
  purrr::list_rbind()
```

```{r, eval=FALSE}
xtabs(~ word + understands_or_says, eng_12)
```

## 18-mo-old English speakers {-}

Let's move on to the 18-mo-old English speakers.

```{r, eval=FALSE}
eng_18_files <- mbcdi_file_dat |>
  dplyr::filter(age_group == '18', lang_cond == 'english', n_subs > 0)
```

There are $n=$ `r dim(eng_18_files)[1]` files with participant data.

```{r, eval=FALSE}
clean_cdi(eng_18_files$fn[1])
clean_cdi(eng_18_files$fn[2])
clean_cdi(eng_18_files$fn[3])
```

There are some duplicate entries for some words.

::: {.rmdnote}

~~We need a strategy for reconciling these duplicates: `candy`, `leg`, `rain`, `wet`.~~

It's not elegant, but I have one for modifying the duplicate names. See below.

:::

## 24-mo-old English speakers {-}

Let's move on to the 24-mo-old English speakers.

```{r, eval=FALSE}
eng_24_files <- mbcdi_file_dat |>
  dplyr::filter(age_group == '24', lang_cond == 'english', n_subs > 0)
```

There are $n=$ `r dim(eng_24_files)[1]` files with participant data.

Let's see how the `clean_cdi()` works on one of these.

```{r, eval=FALSE}
clean_cdi(eng_24_files$fn[1])
```

Once again, we have duplicates for several items: 'candy', 'leg', 'rain', 'wet'.

It's very hacky, but I think we might want to modify these item names until we figure out a better way to handle the duplicates.

```{r, eval=FALSE}
modify_mcdi_dupes <- function(df, dupe = 'leg') {
  dup_index <- seq_along(df)[names(df) == dupe]
  for (i in 1:length(dup_index)) {
    this_dup <- dup_index[i]
    names(df)[this_dup] <- paste0(dupe, "_", i)
  }
  df
}

open_csv <- function(csv_fn) {
  assertthat::is.string(csv_fn)
  assertthat::is.readable(csv_fn)
  
  df <- readr::read_csv(csv_fn,
                    col_types = readr::cols(.default = 'c'),
                    show_col_types = FALSE)
}

trim_cdi_18_24_fields <- function(df) {
  df |>
    dplyr::select(-contains("note"),
                  -contains("instructions"),
                  -contains("comments"),
                  -contains("continue"),
                  -contains("vocab"),
                  -contains("mcdi"))
}

make_cdi_18_24_longer <- function(df) {
  n_vars <- dim(df)[2]
  df |>
    tidyr::pivot_longer(cols = 2:n_vars,
                        names_to = "word",
                        values_to = "knows")
 }

clean_cdi_18_24_dedupe <- function(csv_fn) {
  df <- open_csv(csv_fn)
  names(df) <- basename(names(df))
  
  df |>
    modify_mcdi_dupes(dupe = 'leg') |>
    modify_mcdi_dupes(dupe = 'candy') |>
    modify_mcdi_dupes(dupe = 'rain') |>
    modify_mcdi_dupes(dupe = 'wet') |>
    trim_cdi_18_24_fields() |>
    dplyr::rename("play_id" = "participant_id") |>
    make_cdi_18_24_longer()
}
```

```{r, eval=FALSE}
eng_24 <- purrr::map(eng_24_files$fn, clean_cdi_18_24_dedupe) |>
  purrr::list_rbind()
xtabs(~ word + knows, eng_24)
```

Now, we can return to the 18-mo-old data to see if this works:

```{r, eval=FALSE}
eng_18 <- purrr::map(eng_18_files$fn, clean_cdi_18_24_dedupe) |>
  purrr::list_rbind()
xtabs(~ word + knows, eng_18)
```

It does.

<!--chapter:end:15-mb-cdi.Rmd-->

# Post-visit notes {-}

## Select forms from KBT {-}

The post-visit notes are stored in a separate KBT form with "Post-Visit" in the title.

```
tar_target(kb_post_visit, dplyr::filter(
    kb_df, stringr::str_detect(title, "Post\\-Visit")
  ))
```




<!--chapter:end:18-post-visit-notes.Rmd-->

# Data dictionary {-}

## Background {-}

We make use of the `datadictionary` package here.

This is not a perfect solution.
Among other challenges, this package throws many warnings.
But we will use it for the time being.

## Screening/Demographic data {-}

```{r}
scr_df <- readr::read_csv(paste0(here::here(), "/data/csv/screening/agg/PLAY-screening-datab-latest.csv"),
                          show_col_types = FALSE)

scr_dd <- datadictionary::create_dictionary(scr_df)

readr::write_csv(scr_dd, paste0(here::here(), "/data/csv/screening/dd/PLAY-screening-data-dictionary.csv"))
```

## Screening/Demographic data {-}

```{r}
if (!('home_visit_df' %in% ls())) {
  targets::tar_load(home_visit_df, store=paste0(here::here(), "_targets"))
}
```

```{r}
scr_dd <- datadictionary::create_dictionary(home_visit_df)

readr::write_csv(scr_dd, paste0(here::here(), "/data/csv/home_visit/dd/PLAY-home-visit-data-dictionary.csv"))
```

<!--chapter:end:19-data-dictionary.Rmd-->

# (PART\*) Data Visualization {-} 

<!--chapter:end:20-visualizing.Rmd-->

# Screening visualizations {-}

These visualizations are intended as a way to test the integrity and utility of the data export and cleaning workflow.

## Setup {-}

```{r load-viz-pkgs}
library(targets)
library(tidyverse)
library(forcats)
```

```{r}
screen_df <- readr::read_csv(file.path(here::here(), "data/csv/screening/agg/PLAY-screening-datab-latest.csv"))
```
## Sharing permission {-}

```{r}
(s <- xtabs(~ session_release + group_name, screen_df))
```

Of the $n=$ `r sum(s)` sessions so far, `r 100*(s[1,1]+s[1,2])/sum(s)`% have agreed to EXCERPTS or "Learning Audiences" sharing.

## Dates & times {-}

To calculate cumulative screening/recruiting calls by site, we have to add an index variable

```{r}
df <- screen_df |>
  dplyr::arrange(submit_date) %>%
  dplyr::mutate(n_calls = seq_along(submit_date))
```

### Calls across time {-}

```{r fig-screening-calls-time-series, fig.cap="Cumulative screening calls by year and site"}
df |>
    dplyr::filter(!is.na(submit_date), !is.na(n_calls), !is.na(site_id)) %>%
    ggplot() +
    aes(submit_date, n_calls, color = site_id) +
    geom_point()
```

### Calls by site {-}

```{r fig-screening-calls-by-site, fig.cap="Cumulative screening calls by site"}
calls_by_site_plot <- function(df) {
  df |>
    filter(!is.na(site_id)) %>%
    ggplot() +
    aes(fct_infreq(site_id), fill = site_id) +
    geom_bar() +
    theme(axis.text.x = element_text(
      angle = 90,
      vjust = 0.5,
      hjust = 1
    )) + # Rotate text
    labs(x = "site") +
    theme(legend.position = "none")
}

calls_by_site_plot(df)
```

## Demographics {-}

### Child age {-}

Child age in months (`child_age_mos`) by `child_sex`.

```{r fig-age-hist-screening, fig.cap="Histogram of child age at time of recruiting call."}
screen_df |>
  dplyr::filter(!is.na(child_age_mos), !is.na(child_sex)) |>
  ggplot() +
  aes(child_age_mos, fill = child_sex) +
  geom_histogram(bins = 50)
```

::: {.rmdnote}

Some of the code to clean the `screen_df` variables could be incorporated into an earlier stage of the workflow.

:::

## Language {-}

### To child {-}

Language(s) spoken to child by `child_sex`.

```{r xtabs-language-by-sex}
df <- screen_df |>
  dplyr::mutate(
    language_spoken_child = stringr::str_replace_all(language_spoken_child, " ", "_"),
    language_spoken_home = stringr::str_replace_all(language_spoken_home, " ", "_")
  )

xtabs(formula = ~ child_sex + language_spoken_child,
      data = df)
```

### At home {-}

```{r xtabs-language-at-home-by-sex}
xtabs(formula = ~ child_sex + language_spoken_home, data = df)
```

### To child vs. at home {-}

```{r xtabs-language-child-vs-home}
xtabs(formula = ~ language_spoken_child + language_spoken_home, data = df)
```

## Child health {-}

### Child born on due date {-}

```{r xtabs-duedate-born-on}
xtabs(formula = ~ child_sex + child_bornonduedate,
      data = screen_df)
```

::: {.rmdnote}

There are $n=$ `r sum(is.na(screen_df$child_bornonduedate))` NAs.

:::

```{r}
screen_df |>
  dplyr::filter(is.na(child_bornonduedate)) |>
  dplyr::select(vol_id, participant_ID) |>
  knitr::kable(format = 'html')
```

### Child term {-}

```{r xtabs-duedate}
xtabs(formula = ~ child_bornonduedate + child_onterm,
      data = screen_df)
```

### Child weight {-}

Must convert pounds and ounces to decimal pounds.

```{r fig-birthwt-hist}
df <- screen_df %>%
  dplyr::mutate(.,
                birth_weight_lbs = child_weight_pounds + child_weight_ounces/16)

df |>
  dplyr::filter(!is.na(birth_weight_lbs), !is.na(child_sex)) |>
  dplyr::filter(birth_weight_lbs > 0) |>
  ggplot() +
  aes(x = birth_weight_lbs, fill = child_sex) +
  geom_histogram(binwidth = 0.33) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

### Birth complications {-}

```{r xtabs-birth-compl}
xtabs(formula = ~ child_sex + child_birth_complications,
      data = screen_df)
```

::: {.rmdnote}

There are some first names in the `child_birth_complications_specify` field, so it is not shown here.

:::

```{r table-birth-compl, eval=FALSE}
screen_df |>
  dplyr::filter(!is.na(child_birth_complications_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_birth_complications_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Major illnesses or injuries {-}

```{r xtabs-illness-injuries}
xtabs(formula = ~ child_sex + child_major_illnesses_injuries,
      data = screen_df)
```

```{r table-illness-injuries}
screen_df |>
  dplyr::filter(!is.na(child_illnesses_injuries_specify),
                !stringr::str_detect(child_illnesses_injuries_specify, "OK")) |>
  dplyr::select(child_age_mos, child_sex, child_illnesses_injuries_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child vision {-}

```{r xtabs-vision}
xtabs(formula = ~ child_sex + child_vision_disabilities,
      data = screen_df)
```

```{r table-vision}
screen_df |>
  dplyr::filter(!is.na(child_vision_disabilities_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_vision_disabilities_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child hearing {-}

```{r xtabs-hearing}
xtabs(formula = ~ child_sex + child_hearing_disabilities,
      data = screen_df)
```

```{r table-hearing}
screen_df |>
  dplyr::filter(!is.na(child_hearing_disabilities_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_hearing_disabilities_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child developmental delays {-}

```{r xtabs-dev-delays}
xtabs(formula = ~ child_sex + child_developmentaldelays,
      data = screen_df)
```

::: {.rmdnote}

There may be first names in the `child_developmentaldelays_specify` field, so it is not shown here.

:::

```{r table-dev-delays, eval=FALSE}
screen_df |>
  dplyr::filter(!is.na(child_developmentaldelays_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_developmentaldelays_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child sleep {-}

::: {.rmdimportant}

This is work yet-to-be-done. The time stamps need to be reformatted prior to
visualization.

:::

#### Bed time {-}

```{r fig-bed-time-hist}
extract_sleep_hr <- function(t) {
  t |>
    stringr::str_extract("^[0-9]{2}\\:[0-9]{2}\\:[0-9]{2}") |>
    hms::as_hms()
}

df <- screen_df |>
  dplyr::mutate(child_sleep_time = extract_sleep_hr(child_sleep_time)) |>
  dplyr::filter(!is.na(child_sleep_time)) 

df |>
  dplyr::filter(!is.na(child_sleep_time),
                !is.na(child_sex)) |>
  ggplot() +
  aes(child_sleep_time, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

Some of the bed times are probably not in correct 24 hr time.

```{r}
df |>
  dplyr::filter(child_sleep_time < hms::as_hms("16:00:00")) |>
  dplyr::select(site_id, participant_ID, child_sleep_time) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable('html')
```

#### Wake time {-}

```{r fig-wake-time-hist}
df <- screen_df |>
  dplyr::mutate(child_wake_time = extract_sleep_hr(child_wake_time)) |>
  dplyr::filter(!is.na(child_wake_time)) 

df |>
  dplyr::filter(!is.na(child_wake_time),
                !is.na(child_sex)) |>
  ggplot() +
  aes(child_wake_time, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

There are some unusual wake times, too.

```{r table-wake-time}
df |>
  dplyr::filter(child_wake_time > hms::as_hms("16:00:00")) |>
  dplyr::select(site_id, participant_ID, child_wake_time) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable('html')
```

#### Sleep duration {-}

```{r fig-sleep-dur-hist}
df <- screen_df |>
  dplyr::mutate(child_sleep_time = extract_sleep_hr(child_sleep_time),
                  child_wake_time = extract_sleep_hr(child_wake_time)) |>
  dplyr::filter(!is.na(child_sleep_time),
                !is.na(child_wake_time)) |>
  dplyr::mutate(child_sleep_secs = (child_sleep_time - child_wake_time))

df |>
  dplyr::filter(!is.na(child_sleep_secs)) |>
  ggplot() +
  aes(child_sleep_secs, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

Again, there are some unusual values.

```{r table-sleep-dur}
df |>
  dplyr::filter(child_sleep_secs < 12000) |>
  dplyr::select(site_id, participant_ID, child_sleep_time, child_wake_time, child_sleep_secs) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable('html')
```

#### Nap hours {-}

```{r fig-nap-hrs-hist}
df <- screen_df |>
  dplyr::mutate(child_nap_hours = as.numeric(child_nap_hours)) |>
  dplyr::filter(!is.na(child_sleep_time)) 

df |>
  dplyr::filter(!is.na(child_nap_hours),
                !is.na(child_sex)) |>
  ggplot() +
  aes(child_nap_hours, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

And there are some very long nappers or null values we need to capture.

```{r table-nap-hrs}
df |>
  dplyr::filter(child_nap_hours > 5) |>
  dplyr::select(site_id, participant_ID, child_nap_hours) |>
  dplyr::arrange(site_id, participant_ID) |>
  knitr::kable('html')
```

#### Sleep location {-}

```{r, eval=FALSE}
xtabs(formula = ~ child_sex + child_sleep_location,
      data = screen_df)
```

## Mother {-}

### Biological or adoptive {-}

```{r xtabs-mom-bio}
xtabs(formula = ~ child_sex + mom_bio,
      data = screen_df)
```

### Age at childbirth {-}

```{r fig-mom-age-childbirth}
screen_df |>
  dplyr::filter(!is.na(mom_childbirth_age), !is.na(child_sex)) |>
  ggplot() +
  aes(x = mom_childbirth_age, fill = child_sex) +
  geom_histogram(bins = 25) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

Clearly, there are some impossible (erroneous) maternal ages > 100. Here are details:

```{r table-mom-childbirth}
old_moms <- screen_df |>
  dplyr::filter(mom_childbirth_age > 55)

old_moms |>
  dplyr::select(submit_date, vol_id, participant_ID, mom_childbirth_age) |>
  knitr::kable(format = 'html')
```

### Birth country {-}

```{r xtabs-mom-birth-country}
df <- screen_df |>
  dplyr::mutate(mom_birth_country = dplyr::recode(
    mom_birth_country, 
    unitedstates = "US",
    united_states = "US",
    othercountry = "Other",
    other_country = "Other",
    refused = "Refused"
  ))

xtabs(~ mom_birth_country, data = df)
```

```{r table-mom-birth-country-non-us}
df <- screen_df |>
  dplyr::mutate(mom_birth_country_specify = stringr::str_to_title(mom_birth_country_specify)) |>
  dplyr::filter(!is.na(mom_birth_country_specify)) |>
  dplyr::select(child_sex, mom_birth_country_specify)

unique(df$mom_birth_country_specify)
```

### Education {-}

```{r xtabs-mom-educ}
df <- screen_df |>
  dplyr::filter(!is.na(mom_education)) |>
  dplyr::select(child_sex, mom_education)

xtabs(~ mom_education, data = df)
```

::: {.rmdnote}

This requires some recoding work.

:::

### Employment {-}

```{r xtabs-mom-employ}
df <- screen_df |>
  dplyr::filter(!is.na(mom_employment))

xtabs(~ mom_employment, data = df)
```

### Occupation {-}

This information is available, but would need to be substantially recoded to be useful in summary form.

### Jobs number {-}

```{r xtabs-mom-jobs-number}
df <- screen_df |>
  dplyr::filter(!is.na(mom_jobs_number))

xtabs(~ mom_jobs_number, data = df)
```

```{r xtabs-mom-jobs-vs-employ}
df <- screen_df |>
  dplyr::filter(!is.na(mom_jobs_number),
                !is.na(mom_employment))

xtabs(~ mom_jobs_number + mom_employment, data = df)
```

### Job training {-}

```{r}
df <- screen_df |>
  dplyr::filter(!is.na(mom_training))

xtabs(~ mom_training, data = df)
```

## Childcare {-}

### Types {-}

```{r xtabs-childcare-types}
df <- screen_df |>
  dplyr::filter(!is.na(childcare_types))
                
xtabs(~ childcare_types, data = df)
```

::: {.rmdnote}

This requires some cleaning.

:::

### Hours {-}

```{r childcare-hrs}
df <- screen_df |>
  dplyr::filter(!is.na(childcare_hours)) |>
  dplyr::arrange(childcare_hours)

unique(df$childcare_hours)
```

::: {.rmdnote}

This requires some cleaning.

:::

### Language {-}

```{r child-care-language}
df <- screen_df |>
  dplyr::filter(!is.na(childcare_language))

unique(df$childcare_language)
```

::: {.rmdnote}

This requires some cleaning.

:::

<!--chapter:end:21-viz-screening.Rmd-->

# Demographics visualizations {-}

```{r}
if (!('home_visit_df' %in% ls())) {
  targets::tar_load(home_visit_df, store="../_targets")
}
```

## Child age {-}

Child age in months (`age_group`) by `child_sex`.

Note: The child's exact age in months is part of the Databrary-related data. 
That is on the work plan.

```{r filter-home-visit}
home_visit_filtered <- home_visit_df |>
  dplyr::filter(!is.na(age_group),!is.na(child_sex))
```

```{r}
xtabs(formula = ~ age_group + child_sex, data = home_visit_filtered)
```
A total of $n=$ `r dim(home_visit_filtered)[1]` mother-infant dyads have been tested.
This includes training and pilot visits.

```{r fig-age-grp-by-sex, fig.cap="Participants by age group and sex"}
home_visit_filtered |>
  ggplot() +
  aes(age_group, fill = child_sex) +
  geom_bar() +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

## Time series {-}

To calculate cumulative visits, we have to add an index variable

```{r}
df <- home_visit_filtered |>
  dplyr::select(test_date, site_id) |>
  dplyr::mutate(test_date = as.Date(test_date)) |>
  dplyr::arrange(test_date) |>
  dplyr::mutate(n_calls = seq_along(test_date))
```

```{r fig-home-visit-time-series, fig.cap="Cumulative home visits by year"}
df |>
    dplyr::filter(!is.na(test_date), !is.na(n_calls), !is.na(site_id)) |>
    ggplot() +
    aes(test_date, n_calls) +
    geom_point()
```

<!--chapter:end:22-viz-demographics.Rmd-->

# Language visualizations {-}

```{r}
if (!('home_visit_df' %in% ls())) {
  targets::tar_load(home_visit_df, store="../_targets")
}

library(wordcloud)
library(RColorBrewer)
```

## Language exposure {-}

```{r clean-lang-df}
df <- home_visit_df |>
  dplyr::mutate(language_child = stringr::str_replace_all(language_child, " ", "_"))
xtabs(formula = ~ child_sex + language_child, data = df)
```

## MB-CDI {-}

### 12-mo-old English speakers {-}

```{r}
eng_12 <-
  readr::read_csv(
    "../data/csv/home_visit/agg/mcdi_english_12_combined.csv",
    col_types = readr::cols(.default = 'c'),
    show_col_types = FALSE
  )
```

There are $n=$ `r (n_12_eng <- dim(eng_12)[1])` participant records.

```{r mcdi-12-english}
eng_12_long <- eng_12 |>
  tidyr::pivot_longer(cols = !(play_id | site_id | subject_number),
                        names_to = "word",
                        values_to = "understands_or_says")

#xtabs(~ word + understands_or_says, eng_12_long)
```

```{r}
word_ct <- eng_12_long |>
  dplyr::filter(!is.na(understands_or_says)) |>
  dplyr::filter(understands_or_says == "understands") |>
  dplyr::count(word, sort = TRUE)

quant_25 <- round(n_12_eng*.25, 0)
```

```{r 12-eng-wordcloud}
# rcb_color_paired <- RColorBrewer::brewer.pal(12, 'Paired')
# wordcloud::wordcloud(words = word_ct$word, freq = word_ct$n, min.freq = quant_25, colors = rcb_color_paired)

mcdi_viz_wordcloud(word_ct, n_participants = dim(eng_12)[1], quantile = .40)
```

### 18-mo-old English speakers {-}

```{r}
eng_18 <-
  readr::read_csv(
    "../data/csv/home_visit/agg/mcdi_english_18_combined.csv",
    col_types = readr::cols(.default = 'c'),
    show_col_types = FALSE
  )

```

There are $n=$ `r (n_18_eng <- dim(eng_18)[1])` participant records.

```{r}
word_ct <- eng_18 |>
  tidyr::pivot_longer(cols = !(play_id | site_id | subject_number),
                        names_to = "word",
                        values_to = "says") |>
  dplyr::filter(!is.na(says)) |>
  dplyr::filter(says == TRUE) |>
  dplyr::count(word, sort = TRUE)

quant_25 <- round(n_18_eng*.25, 0)
```

```{r 18-eng-wordcloud}
#wordcloud::wordcloud(words = word_ct$word, freq = word_ct$n, min.freq = quant_25, colors = rcb_color_paired)
mcdi_viz_wordcloud(word_ct, n_participants = dim(eng_18)[1], quantile = .50)
```

### 24-mo-old English speakers {-}

```{r}
eng_24 <-
  readr::read_csv(
    "../data/csv/home_visit/agg/mcdi_english_24_combined.csv",
    col_types = readr::cols(.default = 'c'),
    show_col_types = FALSE
  )
```

There are $n=$ `r dim(eng_24)[1]` participant records.

```{r mcdi-24-english}
word_ct <- eng_24 |>
  tidyr::pivot_longer(cols = !(play_id | site_id | subject_number),
                        names_to = "word",
                        values_to = "says") |>
  dplyr::filter(!is.na(says)) |>
  dplyr::filter(says == TRUE) |>
  dplyr::count(word, sort = TRUE)
```

```{r mcdi-24-eng-word-cloud}
mcdi_viz_wordcloud(word_ct, n_participants = dim(eng_24)[1], quantile = .60)
```

```{r mcdi-24-eng-rare-words-cloud}
rare_word_ct <- word_ct |>
  dplyr::filter(n < dim(eng_24)[1]*.25)
# 
# wordcloud::wordcloud(words = rare_word_ct$word, freq = rare_word_ct$n)
mcdi_viz_wordcloud(rare_word_ct, n_participants = dim(eng_24)[1], quantile = .25)
```


<!--chapter:end:23-viz-language.Rmd-->

# Locomotion visualizations {-}

```{r}
if (!('home_visit_df' %in% ls())) {
  targets::tar_load(home_visit_df, store="../_targets")
}
```

## Select & Summarize {-}

```{r make-loco-df}
play_loco <- home_visit_df %>%
  dplyr::select(
    .,
    age_group,
    child_sex,
    language_child,
    site_id,
    subject_number,
    locomotor_milestones.who_walk.who_walk_onset_mo,
    locomotor_milestones.k_walk.k_walk_onset_mo,
    locomotor_milestones.crawl_onset.crawl_onset_mo
  ) %>%
  dplyr::rename(
    .,
    walk_mos_who = locomotor_milestones.who_walk.who_walk_onset_mo,
    walk_mos_kea = locomotor_milestones.k_walk.k_walk_onset_mo,
    crawl_mos = locomotor_milestones.crawl_onset.crawl_onset_mo
  ) %>%
  dplyr::mutate(
    .,
    walk_mos_who = as.numeric(walk_mos_who),
    walk_mos_kea = as.numeric(walk_mos_kea),
    crawl_mos = as.numeric(crawl_mos)
  )
```

```{r}
xtabs(formula = ~ child_sex + age_group, data = play_loco)
```

### Check for anomalous values {-}

```{r}
crawl_mos_min <- 4
walk_mos_min <- 6
```

#### Anomalous crawling onset {-}

```{r}
play_loco %>%
  dplyr::select(., site_id, subject_number, crawl_mos) %>%
  dplyr::filter(., crawl_mos < crawl_mos_min) %>%
  knitr::kable(format = 'html') 
```

#### Anomalous walking onset (KEA criteria) {-}

```{r}
play_loco %>%
  dplyr::select(., site_id, subject_number, walk_mos_kea) %>%
  dplyr::filter(., walk_mos_kea < walk_mos_min) %>%
  knitr::kable(format = 'html') 
```

##### Anomalous walking onset (WHO criteria) {-}

```{r}
play_loco %>%
  dplyr::select(., site_id, subject_number, walk_mos_who) %>%
  dplyr::filter(., walk_mos_who < walk_mos_min) %>%
  knitr::kable(format = 'html') 
```

### Crawl onset {-}

```{r fig-crawl-onset-hist, fig.cap="Age of crawling onset (mos) by sex"}
play_loco %>%
  dplyr::filter(., crawl_mos > crawl_mos_min, !is.na(crawl_mos)) %>%
  ggplot(.) +
  aes(crawl_mos, fill = child_sex) +
  geom_histogram(bins = 12) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

### Walk onset {-}

```{r fig-walk-mos-kea, fig.cap="Age (mos) of walking onset (KEA criteria) by sex"}
play_loco %>%
  dplyr::filter(., walk_mos_kea > walk_mos_min, !is.na(walk_mos_kea)) %>%
  ggplot(.) +
  aes(walk_mos_kea, fill = child_sex) +
  theme(legend.position="bottom") +
  geom_histogram(bins = 10)
```

```{r fig-walk-mos-who, fig.cap="Age (mos) of walking onset (WHO criteria) by sex"}
play_loco %>%
  dplyr::filter(., walk_mos_who > walk_mos_min, !is.na(walk_mos_who)) %>%
  ggplot(.) +
  aes(walk_mos_who, fill = child_sex) +
  geom_histogram(bins=12) +
  theme(legend.position="bottom") +
  theme(legend.title = element_blank())
```

```{r fig-walk-mos-kea-who, fig.cap="Walking onset by WHO vs. KEA criteria"}
play_loco %>%
  dplyr::filter(., walk_mos_who > walk_mos_min, !is.na(walk_mos_who), walk_mos_kea > walk_mos_min, !is.na(walk_mos_kea)) %>%
  ggplot(.) +
  aes(walk_mos_who, walk_mos_kea, color = child_sex) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlim(8, 18) +
  ylim(8, 18) +
  theme(legend.position = "bottom") +
  theme(aspect.ratio = 1) +
  theme(legend.title = element_blank()) -> walk_p

ggExtra::ggMarginal(
  walk_p,
  play_loco,
  walk_mos_who,
  walk_mos_kea,
  type = "density",
  margins = "both",
  groupColour = TRUE,
  groupFill = TRUE
)
```

```{r fig-walk-mos-kea-crawl-mos, fig.cap="Walking onset vs. Crawling"}
play_loco %>%
  dplyr::filter(., crawl_mos > crawl_mos_min, !is.na(crawl_mos), walk_mos_kea > walk_mos_min, !is.na(walk_mos_kea)) %>%
  ggplot(.) +
  aes(crawl_mos, walk_mos_kea, color = child_sex) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme(legend.position = "bottom") +
  theme(aspect.ratio = 1) +
  theme(legend.title = element_blank()) -> walk_p

ggExtra::ggMarginal(
  walk_p,
  play_loco,
  walk_mos_who,
  walk_mos_kea,
  type = "density",
  margins = "both",
  groupColour = TRUE,
  groupFill = TRUE
)
```

<!--chapter:end:24-viz-locomotion.Rmd-->

# Health visualizations {-}

```{r health-load-home-visit-df}
# Load home_visit_df if not in environment
if (!("health_df" %in% ls())) {
 targets::tar_load(health_df, store="../_targets") 
}
```

## Feeding {-}

```{r}
xtabs(formula = ~ age_group + feeding_breastfeed, data = health_df)
```

```{r fig-solid-food-mos, fig.cap="Age at introduction of solid foods"}
health_df %>%
  dplyr::select(child_sex, feeding_solidfood_age) |>
  dplyr::filter(feeding_solidfood_age < 12) |>
  ggplot() +
  aes(x = feeding_solidfood_age, color = child_sex, fill = child_sex) +
  geom_histogram(bins = 14) +
  theme(legend.title = element_blank())
```

Clearly, there are some impossible values here.

```{r anomalous-feeding}
health_df |>
  dplyr::select(participant_id, feeding_solidfood_age) |>
  dplyr::filter(feeding_solidfood_age > 12) %>%
  knitr::kable(format = 'html')
```

A preliminary look at `feeding_comments_feeding` shows that there are some names mentioned.

::: {.rmdnote}

We should consider flagging these in the QA process.

:::

## Sleeping position {-}

These data only focus on `child_sleeping_position`.
Other sleeping data are in the screening questionnaire.

```{r}
sleeping_pos <- health_df |>
  dplyr::select(child_sex, age_group, child_sleeping_position) |>
  dplyr::filter(!is.na(child_sleeping_position))

xtabs(formula = ~ child_sleeping_position + age_group, data = sleeping_pos)
```

## Smoking/drinking {-}

```{r tab-smoking-drinking}
smoking_drinking <- health_df |>
  dplyr::select(age_group,
    child_sex,
    contains("smoking"),
    contains("drinking")
  )

xtabs(formula = ~ pregnant_smoking + pregnant_drinking, smoking_drinking)
```

```{r tab-smoking-house-car}
xtabs(formula = ~ smoking_house + smoking_car, smoking_drinking)
```

```{r tab-comments-smoking}
smoking_drinking |>
  dplyr::select(comments_smoking) |>
  dplyr::filter(!is.na(comments_smoking)) |>
  knitr::kable(format = 'html')
```

```{r tab-comments-drinking}
smoking_drinking |>
  dplyr::select(comments_drinking) |>
  dplyr::filter(!is.na(comments_drinking)) |>
  knitr::kable(format = 'html')
```

## Patient Health Questionnaire (PHQ-4) {-}

```{r fig-phq4, fig.cap="PHQ4 responses by age group and child sex"}
phq4 <- health_df |>
  dplyr::select(child_sex, age_group, contains("phq4_"))

names(phq4) <- gsub(pattern = "phq4_", 
                    replacement = "",
                    names(phq4))

phq4 |>
  tidyr::pivot_longer(!c('child_sex', 'age_group'), names_to = "question", values_to = "response") |>
  dplyr::filter(!is.na(response)) |>
  dplyr::mutate(response = factor(response,
                                  c("notatall",
                                    "severaldays",
                                    "morethanhalf",
                                    "nearly")),
                ordered = TRUE) |>
  ggplot() +
  aes(x = response, fill = child_sex) +
  geom_bar() +
  facet_grid(cols = vars(question), rows = vars(age_group)) +
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  xlab("") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

## Child health {-}

### Overall rating  {-}

```{r tab-child-health-rating}
child_health_rating <- health_df |>
  dplyr::select(child_sex, age_group, child_health) |>
  dplyr::filter(!is.na(child_health)) |>
  dplyr::mutate(child_health = factor(child_health,
                                      c("poor",
                                        "fair",
                                        "good",
                                        "verygood",
                                        "excellent",
                                        "donotknow",
                                        "refused"),
                                      ordered = TRUE))

xtabs(formula = ~ child_health + age_group, data = child_health_rating)
```
### Recent vaccination {-}

```{r}
recent_vax <- health_df |>
  dplyr::select(child_sex, age_group, child_vaccination) |>
  dplyr::filter(!is.na(child_vaccination))

xtabs(formula = ~ child_vaccination + age_group, data = recent_vax)
```
### Seen medical specialist {-}

```{r}
seen_specialist <- health_df |>
  dplyr::select(child_sex, age_group, child_medical_specialist) |>
  dplyr::filter(!is.na(child_medical_specialist))

xtabs(formula = ~ child_medical_specialist + age_group, data = seen_specialist)
```
::: {.rmdnote}

Manual inspection shows some possible identifying information (names) in the comments.

:::

### Illnesses and allergies {-}

```{r fig-illness-allergies}
illness_allergy <- health_df |>
  dplyr::select(child_sex, age_group, contains("illness_"))


names(illness_allergy) <- gsub(pattern = "illness_",
                               replacement = "",
                               names(illness_allergy))

illness_allergy |>
  tidyr::pivot_longer(!c('child_sex', 'age_group'),
                      names_to = "type",
                      values_to = "response") |>
  dplyr::filter(!is.na(response)) |>
  dplyr::mutate(response = factor(response,
                                  c("no", "yes", "donotknow", "refused"))) |>
  ggplot() +
  aes(x = response, fill = child_sex) +
  geom_bar() +
  facet_grid(cols = vars(type), rows = vars(age_group)) +
  scale_x_discrete(guide = guide_axis(angle = 90)) +
  xlab("") +
  theme(legend.position = "bottom", legend.title = element_blank())
```

<!--chapter:end:25-viz-health.Rmd-->

# Temperament visualizations {-}

This page provides visualizations of the Early Childhood Behavior Questionnaire (ECBQ) data related to child temperament.

## Setup {-}

As of 2023-09-21, this workflow uses a separate set of functions specifically designed to extract ECBQ data from the raw KoBoToolbox files for *English-speaking families only*.

The functions are found in `R/` with the prefix `ecbq_`.

We create a "wide" data frame `ecbq_wide_df` as one of the targets of `targets:tar_make()`.
We attempt to load that here and ensure that all `R/ecbq_` functions are in the local environment.

```{r}
if (!('ecbq_wide_df' %in% ls())) {
  targets::tar_load(ecbq_wide_df, store="../_targets")
}

if (!('ecbq_plot_all' %in% ls())) {
  ecbq_fl <- list.files("../R", "^ecbq_", full.names = TRUE)
  purrr::walk(ecbq_fl, source)
}
```

## Summarize {-}

```{r}
ecbq_complete <- ecbq_wide_df |>
  tidyr::complete()

str(ecbq_complete)
```

```{r tab-ecbq-age-by-sex-cases}
xtabs(formula = ~ age_group + child_sex, ecbq_complete)
```

## Visualize {-}

```{r}
ecbq_vars <- names(ecbq_complete)[stringr::str_detect(names(ecbq_complete),"rothbart_")]

# Omit comments
ecbq_vars <- ecbq_vars[!stringr::str_detect(ecbq_vars, "comments")]
```

We use `purrr::map()` to plot all of the responses to individual ECBQ items.

```{r purrr-map-ecbq-figs}
purrr::map(ecbq_vars, suppressMessages(ecbq_plot), df = ecbq_complete)
```

### Comments {-}

Manual inspection shows that the comments field has some names.
We omit printing the comments here until we can be assured that there is no identifiying information in the comments.

```{r ecbq-comments, eval=FALSE}
ecbq_complete |>
  dplyr::select(participant_id, age_group, rothbart_comments) |>
  dplyr::filter(!is.na(rothbart_comments)) |>
  dplyr::arrange(age_group) |>
  knitr::kable(format = 'html')
```



<!--chapter:end:26-viz-temperament.Rmd-->

# Post-visit data {-}

We load the post-visit survey data.

```{r load-post-visit-df}
tar_load(post_visit_df, store="../_targets")

dim(post_visit_df)
```

::: {.rmdnote}

Cleaning this data is set aside for future work.

:::

<!--chapter:end:29-post-visit.Rmd-->

# (PART\*) Project Monitoring {-} 

<!--chapter:end:30-management.Rmd-->

