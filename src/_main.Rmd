---
title: "PLAY Project: Surveys"
author: "Rick Gilmore"
date: "`r Sys.Date()`"
bibliography: ['include/bib/book.bib', 'include/bib/packages.bib']
css: include/css/styles.css
description: "Protocol for processing PLAY Project survey data"
output: 
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 2
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center",
                      fig.path = "include/img/")
library(tidyverse)
```

# About {-}

```{r, echo=FALSE, out.width="75%", fig.link='https://play-project.org'}
knitr::include_graphics("include/img/PLAY-logo.png")
```

## Purpose {-}

PLAY project researchers use [KoBoToolbox](https://www.kobotoolbox.org/) to collect data from participant families.
Data from all sessions at all PLAY data collection sites are pushed to a common set of files on the KoBoToolbox server.

This document describes the process of i) downloading, ii) parsing, iii) cleaning, and iv) exporting these files into forms more suitable for data analysis.

For details about the PLAY Project data collection protocol, see <https://PLAY-behaviorome.github.io/protocol/>.

## Overview of data sets {-}

There are three sets of data collected using KoBoToolbox.
One set is collected during the recruiting and screening calls for the study.
The second set is collected during the home visit.
The third set consists of notes generated by the experimenter after the visit.

### Data access and processing {-}

All data are downloaded and manipulated locally but are **not** synched to GitHub.
This is accomplished by adding `data` to [`.gitignore`](.gitignore).

There are separate processes for detecting and deleting personal identifiers from specific data files and exporting 'cleaned' versions that may be shared on Databrary.

### Home visit data {-}

There are three (3) age groups (12-, 18-, and 24-month-olds) and four (4) different language environment groups (English-only, Spanish-only, Bilingual-English-dominant, Bilingual-Spanish-dominant).
Since the language of the questions and some of the specific questions vary by age group and by language environment group, there multiple KoBoToolbox survey form files that must be processed.

<!--chapter:end:index.Rmd-->

# (PART\*) Tools and Processes {-} 

<!--chapter:end:00-tools.Rmd-->

# Setup {-}

This section describes the setup procedure.

## Authentication {-}

The data are stored in an account on <https://kf.kobotoolbox.org>. 
The login credentials for that account are shared among the PLAY Project staff. 
To access the site's API programmatically, an API key was downloaded and added to the local `~/.Renviron` file.

<!-- https://bookdown.org/yihui/bookdown/html.html#callout-blocks -->
<!--Available blocks are: .rmdnote, .rmdcaution, .rmdimportant, .rmdtip, and .rmdwarning -->
::: {.rmdimportant}

The KoBoToolBox API key is **not** synched to GitHub.

:::


## Set-up {-}

To test whether the local system has the API key installed, we run the command `Sys.getenv("KOBO_API_KEY")`. 

### Check KoBo API Key {-}

```{r check-api-key}
kb_api <- Sys.getenv("KOBO_API_KEY")
if ((length(kb_api) != 1) || (!is.character(kb_api))) {
  stop("'KOBO_API_KEY' not installed in .Renviron")
} else {
  message("'KOBO_API_KEY' installed.")
}
```

### Check Databrary credentials {-}

The `databraryapi` package handles authenticating to Databrary.
For scripting access to Databrary that require authentication, it is useful to store the user's Databrary login (email) in `.Renviron` using the R command `Sys.setenv(DATABRARY_LOGIN = "<email@provider.com>")` where you substitute your Databrary login (email) for `<email@provider.com>`.
When this has been accomplished the following code can be run to check the status of the saved variable.

```{r}
db_logon <- Sys.getenv("DATABRARY_LOGIN")
if ((length(db_logon) != 1) || (!is.character(db_logon)) || (db_logon == "")) {
  stop("'DATABRARY_LOGIN' not installed in .Renviron")
} else {
  message("'DATABRARY_LOGIN' installed.")
}
```

### Install dependencies {-}

We now use the [`renv`](https://cran.r-project.org/web/packages/renv/index.html) package to manage package dependencies.

### Load/source helper functions {-}

Most of the work is contained in `R/functions.R`.
This is sourced when we run `tar_make()` from the `{targets}` package.

::: {.rmdimportant}
We run `targets::tar_make()` manually for the time being.

None of the outputs are synced to GitHub.
:::

## Approach

To make the workflow more robust and reproducible, much of the work is embedded in functions and extensive use is made of the [`{targets}`](https://cran.r-project.org/web/packages/targets/) package. 
This document describes the workflow, but none of these code chunks are executed.

We leave execution to the `targets::tar_make()` function which updates components as needed.

:::{.rmdnote}
I am currently working on implementing most of the functions using the `box` package. This allows better isolation of dependencies within different components of the workflow.

The box-related functions are in a new `play/` directory, and the R source files are divided into categories.
The functions related to processing the screening/demographic data are in `play/screen.R`.

They will be loaded into the workspace via `box::use(play/screen)` or for modules within `play/` via `box::use(./screen)`.
:::

<!--chapter:end:01-setup.Rmd-->

# (PART\*) Data Wrangling {-} 

<!--chapter:end:10-wrangling.Rmd-->

# Screening call {-}

## Collection protocol {-}

Details about the data collection [protocol for participant screening and recruiting](https://www.play-project.org/collection.html#Participant_Recruitment) can be found on the [PLAY Project website](https://play-project.org).

## Retrieve from KoBoToolbox (KBT) {-}

### Setup {-}

Load functions needed to download KBT screening/demographic questionnaire files.

```{r}
kb_fl <- list.files(file.path(here::here(), "R"), "^kobo_", full.names = TRUE)
purrr::walk(kb_fl, source)

file_fl <- list.files(file.path(here::here(), "R"), "^file_", full.names = TRUE)
purrr::walk(file_fl, source)
```

### Download {-}

First, we list the screening call data files available on KBT.

```{r list-demographic-from-kbt}
(kb_screen_df <- kobo_list_data_filtered("[Dd]emographic"))
```

Then we retrieve and save these files.

```{r download-demographic-from-kbt}
kobo_retrieve_save_many_xlsx(kb_screen_df, save_dir = "../data/xlsx/screening")
```

Next, we convert the XLSX files to CSVs via a function from the `play/files` module.

```{r save-demographic-as-csv}
file_load_xlsx_save_many_csv("../data/xlsx/screening", "../data/csv/screening", "Demographic")
```

## Clean and merge {-}

### Setup {-}

A set of cleaning functions have the `screen_` prefix.

```{r}
purrr::walk(list.files(file.path(here::here(), "R"), 
                    "^screen_", full.names = TRUE), source)
```

There are three CSV files to clean:

```{r}
(fn <- list.files("../data/csv/screening", "[Dd]emographic", full.names = TRUE))
```

We clean them separately, as needed, then merge them.

### Clean variable names {-}

```{r read-screening-csvs}
df1 <-
  readr::read_csv(fn[1],
                  col_types = readr::cols(.default = 'c'),
                  show_col_types = FALSE)
df2 <-
  readr::read_csv(fn[2],
                  col_types = readr::cols(.default = 'c'),
                  show_col_types = FALSE)
df3 <-
  readr::read_csv(fn[3],
                  col_types = readr::cols(.default = 'c'),
                  show_col_types = FALSE)
```

```{r}
head(names(df1), 15)
```

```{r}
head(names(df2), 15)
```

```{r}
head(names(df3), 15)
```

There are a separate set of variable-by-variable cleaning functions in `R/screen_clean_utils.R`.

We remove the unneeded 'play_demo_*' and 'play_phone_questionnaire_' variable headers using `screen_remove_variable_headers()`.

We remove fields that contain administrative metadata with `screen_remove_metadata_fields()`.

We remove fields used only by staff in uploading data to Databrary using `screen_remove_databrary_fields()`.

We have name and address information in the screening data (e.g., '..parent_phone', '..parent_email', etc.) 

::: {.rmdnote}

In a future workflow, we will add Census FIPS IDs for the State and Country 
**before** removing the address information.

The Census queries stopped working around 2023-06-16.

For now, we remove identifiers without querying the Census.

:::

We remove identifiable information using `screen_remove_identifiers()`.

Then, we use `dplyr::full_join()` to combine the set of individually 
cleaned data files.
The `screen_clean_raw_csv()` function combines the previous `screen_remove*` functions.
The `screen_clean_raw_join()` function cleans each CSV then joins them.

```{r clean-screening-join}
(scr_df <- screen_clean_raw_join())
```

### Clean individual fields {-}

Now, we can proceed to clean-up the merged data frame.
The sequence of functions called below cleans 'construct-specific' variables
as indicated by the function names.

```{r show-screening-field-cleaning, eval=FALSE}
scr_df <- scr_df |> 
    screen_clean_child_info() |>
    screen_clean_lang_info() |>
    screen_clean_mom_info() |>
    screen_clean_biodad_father_info() |>
    screen_clean_childcare_info() |>
    screen_clean_family_structure() |>
    screen_clean_play_id() |>
    screen_remove_selected_cols() |>
    screen_select_reorder_cols()
```

For convenience, we package this sequence in its own function, `screen_clean_fields()`.

::: {.rmdnote}

Note that all of the variables are considered character strings. The `tidyverse`
suite does a great job of guessing what variables are what, but sometimes it
guesses wrongly. So, in preliminary stages, it has proved easier to make everything
a character string.

:::

```{r clean-merged-screen-fields}
scr_df <- screen_clean_fields(scr_df)
str(scr_df)
```

There is more work to do, but we have a version worth exporting.

## Export cleaned file {-}

We date-stamp the exported file so we can monitor progress as this workflow develops.

```{r export-screen}
sfn <- paste0("PLAY-screening-", Sys.Date(), ".csv")
readr::write_csv(scr_df, file.path(here::here(), "data/csv/screening/agg/", sfn))
```

<!--chapter:end:12-screening.Rmd-->

# Home visit {-}

## Protocol {-}

Details about the data collection protocol for the home visit can be found on the [PLAY Project website](https://www.play-project.org/collection.html#Home_Visit).

## Overview {-}

The notes below summarize the steps needed to process the home visit survey data.
Most of the R chunks are **not** run, however, since we have moved the work into a [`\{targets\}`](https://docs.ropensci.org/targets/)-based workflow.

## Download data {-}

Data files for each of the language by age-group conditions are stored on KoBoToolbox (KBT).

Store all of the data files on KBT in `kb_df`.

```
tar_target(kb_df, list_kobo_data()),
```

```{r home-visit-list-forms, eval=FALSE}
library(targets)
targets::tar_load(kb_df, store="../_targets")
kb_df
```

List data forms specific to the home visit by filtering the files with names that contain "Home".

```
tar_target(kb_home, dplyr::filter(kb_df, stringr::str_detect(title, "Home")))
```

```{r home-visit}
targets::tar_load(kb_home, store="../_targets")
kb_home
```

### Save selected raw files to local directory {-}

Prepare to retrieve all home visit files.

```{r}
n_files <- dim(kb_home)[1]
```

There are $n=$ `r dim(kb_home)[1]` home visit data files.

```
tar_target(
  home_visit_downloads,
  retrieve_kobo_xlsx(kb_home, 
    "data/xlsx/home_visit/raw"),
  cue = tarchetypes::tar_cue_age(
    name = home_visit_downloads,
    age = as.difftime(update_interval, 
      units = update_interval_units)
  )
)
```

### Normalize file names {-}

Some of the form names are inconsistent, so we normalize them to fit the following pattern:

`<form_id>_PLAY_HomeQuestionnaires_<age_group>_<lang_group>.xlsx`

```
tar_target(
  home_visit_renamed,
  rename_home_xlsx(home_visit_downloads,
                     "data/xlsx/home_visit/std_name"),
  cue = tarchetypes::tar_cue_age(
    name = home_visit_renamed,
    age = as.difftime(update_interval, 
      units = update_interval_units)
  )
)
```

### Save xlsx as csv {-}

```
tar_target(
  home_visit_xlsx_to_csv,
  load_xlsx_save_many_csvs_2(home_visit_renamed, 
    "data/csv/home_visit/raw")
)
```

### Split MB-CDI from other questions {-}

Next we import a CSV for a given form year, age group, and language group, and create two new CSV files: one with the MB-CDI data and one with all of the other survey questions.

By default, the document presumes that we want to convert **all** of the CSV files

Extract the 'non-mbcdi' questions first and add 'non_mbcdi' to the filename.

```
tar_target(
  home_visit_non_mbcdi,
  split_non_mbcdi_csvs(home_visit_xlsx_to_csv,
                        "data/csv/home_visit/non_mbcdi")
)
```

Extracting the MB-CDI data has nearly the same function call, but the `these_questions` parameter is set to 'mbcdi'.

```
tar_target(
  home_visit_mbcdi,
  split_mbcdi_csvs(home_visit_xlsx_to_csv,
                    "data/csv/home_visit/mbcdi")
)
```

## Clean data {-}

### Remove identifiers {-}

The function `remove_identifiers()` in `R/kobo_export` detects the presence of names, addresses, phone numbers, email, and dates in the field names for an input file and removes these fields.
It also modifies the file name by appending `_deidentified`.

The `remove_identifiers()` function detects these fields
For clarity, we print it here.

```{r}
source("~/rrr/KoBoToolbox/R/_OLD/functions.R", echo = FALSE, print.eval = FALSE)
remove_identifiers
```

The **non-MBCDI file** contains the identifiers, so that is the target of this removal process.

::: {.rmdnote}
Note that we have added `data` to `.gitignore` in `protocol/`, the root directory for the HTML protocol, so *none* of the data files should be made available via git or GitHub. This also means that there is **no version control** being done on raw data files themselves.
:::

```
tar_target(
  home_visit_remove_identifiers,
  purrr::map_chr(
    home_visit_non_mbcdi,
    open_deidentify_save,
    csv_save_dir = "data/csv/home_visit/non_mbcdi/deid",
      these_questions = 'non_mbcdi'
  )
)
```

## Quality assurance (QA) reviews {-}

### MB-CDI files {-}

### Non-MB-CDI files {-}

Create a helper function to create a data set with summary information about the data files.

```{r define-qa-helper}
summarize_non_mbcdi_qs <- function(fn) {
  stopifnot(is.character(fn))
  
  if (!file.exists(fn)) {
    stop('File not found `', fn, '`')
  } else {
    df <- readr::read_csv(fn, show_col_types = FALSE)
    if (!is.data.frame(df)) {
      stop('Error reading data frame')
    } else {
      out_df <-
        tibble(
          file_name = basename(fn),
          n_rows = dim(df)[1],
          n_vars = dim(df)[2]
        )
      dplyr::arrange(out_df, file_name)
    }
  }
}
```

Select the de-identified CSVs to examine.

```{r generate-qa-report}
fl <-
  list.files(
    file.path("../data/csv/home_visit/non_mbcdi/deid"),
    '^[0-9]+_non_mbcdi_[12|18|24].*deidentified',
    full.names = TRUE
  )

PLAY_forms <- purrr::map_df(fl, summarize_non_mbcdi_qs)

PLAY_forms %>%
  knitr::kable(., format = 'html') %>%
  kableExtra::kable_classic()
```

The later forms (with higher form numbers--the leading integers in the file names) are the newer ones.
These generally have the largest number of entries and have similar numbers of columns--either 287 or 288.
Accordingly, we focus our cleaning efforts here first.

We start with the data files that have $n=288$ columns.

```{r}
df740623 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740623_non_mbcdi_12_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )

df740624 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740624_non_mbcdi_12_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740623) == names(df740624))
```

```{r}
df740625 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740625_non_mbcdi_12_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740623) == names(df740625))
```

```{r}
df740628 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740628_non_mbcdi_18_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740623) == names(df740628))
```

So, four of the most recent data files with $n=288$ columns can be aggregated without modification.

Let's turn to the more recent files with $n=287$ columns.

```{r}
df740626 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740626_non_mbcdi_18_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )

df740627 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740627_non_mbcdi_18_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740627))
```

Where does the misalignment arise?

```{r}
names(df740626) == names(df740627)
```

The misalignment arises somewhere near column 92.

```{r}
df740629 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740629_non_mbcdi_24_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740629))
```

So, `df740626` and `df740629` are aligned and can be merged.

```{r}
df740630 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740630_non_mbcdi_24_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740630))
names(df740626) == names(df740630)
```

These files also fall out of alignment near column 92.

```{r}
df740631 <-
  readr::read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/740631_non_mbcdi_24_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )

sum(names(df740626) == names(df740631))
names(df740626) == names(df740631)
```

And these files fall out of alignment near column 92.

Let's see if `df740627`, `df740630`, and `df740631` are aligned with one another.

```{r}
sum(names(df740627) == names(df740630))
sum(names(df740627) == names(df740631))
```

Yes, they are. So, these three can be merged. 
We do that first, then address the discrepancies between aggregates.

### 'Older' forms {-}

The "older" forms have varied numbers of columns.
We focus on thos with data (n_vars > 0)

```{r}
df307736 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/307736_non_mbcdi_18_english_deidentified.csv",
    show_col_types = FALSE
  )
df331453 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/331453_non_mbcdi_24_english_deidentified.csv",
    show_col_types = FALSE
  )
df331848 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/331848_non_mbcdi_12_english_deidentified.csv",
    show_col_types = FALSE
  )
df334099 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/334099_non_mbcdi_12_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )
df363349 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/363349_non_mbcdi_18_english_deidentified.csv",
    show_col_types = FALSE
  )
df363381 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/363381_non_mbcdi_24_english_deidentified.csv",
    show_col_types = FALSE
  )
df363431 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/363431_non_mbcdi_12_english_deidentified.csv",
    show_col_types = FALSE
  )
df408149 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/408149_non_mbcdi_24_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )
df411456 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/411456_non_mbcdi_12_bilingual_english_deidentified.csv",
    show_col_types = FALSE
  )
df411469 <-
  read_csv(
    "../data/csv/home_visit/non_mbcdi/deid/411469_non_mbcdi_12_bilingual_spanish_deidentified.csv",
    show_col_types = FALSE
  )
```

Let's look at the two forms that have the same number of columns, $n=274$, 307736 and 331453.

```{r}
names(df307736) == names(df331453)
length(names(df307736) == names(df331453)) == length(names(df307736))
```
So, these two are identical and could be merged.

```
tar_target(files_274_cols, stringr::str_detect(home_visit_remove_identifiers, "/(307736|331453)"))

tar_target(df_merge_274_cols, make_aggregate_data_file(home_visit_remove_identifiers[files_274_cols]))
```

How about the files with $n=267$ columns, 331848 and 334099?

```{r}
names(df331848) == names(df334099)
length(names(df331848) == names(df334099)) == length(names(df331848))
```

```{r}
names(df331848) |> head()
names(df334099) |> head()
```
There is an odd difference in the group label, `group_combinedquestionnaires` vs. `group_jo84c13`.

Let's try deleting the initial group labels and compare again.

```{r}
n1 <- names(df331848)
n2 <- names(df334099)

names(df331848) %>% stringr::str_remove("group_combinedquestionnaires/") |> head()
names(df334099) %>% stringr::str_remove("group_jo84c13/") |> head()
```
That looks promising.

```{r}
names(df331848) %>% stringr::str_remove("group_combinedquestionnaires/") -> n1
names(df334099) %>% stringr::str_remove("group_jo84c13/") -> n2
n1 == n2
```
```{r}
cbind(n1[8:15], n2[8:15])
```
`n2` or `df334099` has a `child_birth_date` field in position 9 that the other data frame does not have.

```{r}
n1 |> str_detect("child_birth_date") |> sum()
```

If we delete that variable, the data frames will no longer have the same number of columns.
Let's explore that anyway.

```{r}
n2_2 <- n2[-9]

n1 == n2_2
```
That helps a bit, but we diverge around column 29.

```{r}
cbind(n1[28:51], n2_2[28:51])
```

These question labels looks very similar.
There are just some minor changes in the variable names.
`n2_2` has an extra variable in column 40.

```{r}
n2_3 <- n2_2[-40]
```

Then, we can rename some of the columns in `n2_3` using corresponding names from `n1`.

```{r}
n2_3 |> stringr::str_replace("yes__in_the_bi", "birthhospital") |> stringr::str_replace("yes__after_goi", "afterhome") |> stringr::str_replace("don_t_know", "donotknow") -> n2_4

n1 == n2_4
```

```{r}
cbind(n1[39:51], n2_4[39:51])
```

`n1` has a `group_medicalprof` label from `allergies` through `gastrointestinal`; `n2_4` has `child_allergies_infections_ill` for the same questions.

```{r}
n2_4 |> stringr::str_replace("child_allergies_infections_ill", "group_medicalprof") -> n2_5
n1 == n2_5
```


```{r}
cbind(n1[49:60], n2_5[49:60])
```

It looks like these could be reconciled by deleting `prenatal_care` from `n1`.

```{r}
n1_2 <- n1[-50]
n1_2 == n2_5
```
```{r}
cbind(n1_2[64:75], n2_5[64:75])
```

It looks like the phq4 is *not* in `n2_5`.

Let's check.

```{r}
n2_5 |> stringr::str_detect("phq4") |> sum()
```

Yes, there are only two PHQ4-related questions in `df334099`.

```{r}
df334099 |> names() |> stringr::str_detect("phq4") |> sum()
```

This path of reconciliation does not appear fruitful.

## Make aggregate files {-}

### non-MB-CDI files with $n=288$ columns {-}

```
tar_target(files_288_cols, 
  stringr::str_detect(home_visit_remove_identifiers, 
                      "2[3458]_non_mbcdi.*_deidentified\\.csv")
)

tar_target(df_merge_288_cols,
    make_aggregate_data_file(
        home_visit_remove_identifiers[files_288_cols])
)
```

### non-MB-CDI files with $n=287$ columns {-}

```
tar_target(files_287_cols_1, 
  stringr::str_detect(home_visit_remove_identifiers, 
          "2[69]_non_mbcdi.*_deidentified\\.csv")),
tar_target(files_287_cols_2, 
  stringr::str_detect(home_visit_remove_identifiers, 
          "(740627|740630|740631)_non.*_deidentified\\.csv")),
tar_target(df_merge_287_cols_1,
  make_aggregate_data_file(
          home_visit_remove_identifiers[files_287_cols_1])),
tar_target(df_merge_287_cols_2,
  make_aggregate_data_file(
          home_visit_remove_identifiers[files_287_cols_2])),
```

### Examine groups with $n=287$ cols {-}

We focus on the starting column where the column names diverge, column 92.

```{r}
targets::tar_load(df_merge_287_cols_1, store="../_targets")
targets::tar_load(df_merge_287_cols_2, store="../_targets")
names(df_merge_287_cols_1)[92]
names(df_merge_287_cols_2)[92]
```

There is an erroneous `group_locomotor_milestones.` in the `df_merge_287_cols_2` column name.

A bit of sleuthing determines that this `group_locomotor_milestones.` label is characteristic of columns 92 to 273.

```{r}
names(df_merge_287_cols_2)[92:273] |> stringr::str_detect(pattern = "group_locomotor_milestones")
```

The following should fix this.

```{r}
old_names <- names(df_merge_287_cols_2)
new_names <- old_names
new_names[92:273] <-
  stringr::str_remove(new_names[92:273], "group_locomotor_milestones\\.")
names(df_merge_287_cols_2) <- new_names
```

```{r}
names(df_merge_287_cols_2) == names(df_merge_287_cols_1)
```

We have a second problem with columns from 114 to 210.

```{r}
rbind(names(df_merge_287_cols_1)[113:115], names(df_merge_287_cols_2)[113:115])
```

One of the problems has to do with column 114. There is a question ending `doctor_told_you` in `names(df_merge_287_cols_1)` but not in `names(df_merge_287_cols_2)`.

```{r}
names(df_merge_287_cols_1) |> stringr::str_detect(pattern = "doctor_told_you") |> sum()
names(df_merge_287_cols_2) |> stringr::str_detect(pattern = "doctor_told_you") |> sum()
```

Deleting this question would create additional misalignments and further problems.
We cannot proceed without further discussion with our team.

For now, let's generate an array with all of the remaining differences in column names.

```{r}
names_differ <- (names(df_merge_287_cols_2) != names(df_merge_287_cols_1))
sum(names_differ)
```

```{r}
rbind(names(df_merge_287_cols_1)[names_differ], names(df_merge_287_cols_2)[names_differ])
```

Visual inspection suggests that these are similar with the following deviations:

- As noted, `df_merge_287_cols_1` has a column ending `doctor_told_you` that is not present in `df_merge_287_cols_2`.
- `df_merge_287_cols_2` has a column ending `technology_use_scale` that is not present in the `df_merge_287_cols_1`
- There are a set of fields in `group_databrary` that do not align exactly. We will almost certainly delete these, so the misalignment is not a huge problem.

As an exploration, let's see if we can reconcile these by deleting the non-aligning columns.

```{r}
df1 <- df_merge_287_cols_1
df2 <- df_merge_287_cols_2

df1 <- df1 %>%
  dplyr::select(., -contains('doctor_told_you'))

df2 <- df2 %>%
  dplyr::select(., -contains('technology_use_scale'))

old_names <- names(df2)
new_names <- old_names
new_names[92:273] <- stringr::str_remove(new_names[92:273], "group_locomotor_milestones\\.")
names(df2) <- new_names

names(df1) == names(df2)
```

This looks promising.

```{r}
rbind(names(df1)[263], names(df2)[263])
```

This is easily fixed.

```{r}
names(df1)[263] <- names(df2)[263]
```

```{r}
rbind(names(df1)[273:275], names(df2)[273:275])
```

The last misalignments relate to Databrary fields.

```{r}
df1 <- df1 %>%
  dplyr::select(., -contains('group_databrary'))

df2 <- df2 %>%
  dplyr::select(., -contains('group_databrary'))

names(df1) == names(df2)
```

Success!

## Combining the two groups of datasets {-}

Now, let's go back to the data frame with 288 cols and see if we can bring these into alignment.

```{r}
targets::tar_load(df_merge_288_cols, store="../_targets")

df3 <- df_merge_288_cols

df3 <- df3 %>%
  dplyr::select(., -contains('group_databrary'))

c(dim(df1), dim(df2), dim(df3))

names(df1) == names(df3)
rbind(names(df1)[114:115], names(df3)[114:115])
```

Once again, there appears to be a problem with the 'doctor_told_you' field. We'll delete it to see if this fixes one of the problems.

```{r}
df3 <- df3 %>%
  dplyr::select(., -contains('doctor_told_you'))

names(df1) == names(df3)
```

We still have misalignments at column 210.

```{r}
rbind(names(df1)[210:213], names(df3)[210:213])
```

The 'technology_use_scale` exists in one but not the other.

```{r}
df3 <- df3 %>%
  dplyr::select(., -contains('technology_use_scale'))

rbind(dim(df1), dim(df3))

names(df1) == names(df3)
```

:::{.rmdimportant}
Future versions of the workflow will need to handle this more elegantly. 

Option 1: Fix the underlying forms.

Option 2: Add the 'missing' columns as NA in post-processing.
:::

For now, I'm going to create functions that align these data frames.
These are incorporated into `R/functions.R` so we do not source them again here.

```{r, eval=FALSE}
remove_technology_use_scale <- function(df) {
  dplyr::select(df, -contains('technology_use_scale'))
}

remove_doctor_told_you <- function(df) {
  dplyr::select(df, -contains('doctor_told_you'))
}

remove_databrary_fields <- function(df) {
  dplyr::select(df, -contains('group_databrary'))
}

reconcile_typicalday <- function(df) {
  names(df) <- stringr::str_replace_all(names(df), 'typicalday', 'typical_day')
  df
}

remove_permissive_locomotor_milestones_label <- function(df) {
  old_names <- names(df)
  new_names <- old_names
  contains_locomotor <-
    stringr::str_detect(new_names, pattern = "locomotor_milestones.*health|division|rothbart|mediause|pets|typical|acknowledge")
  new_names[contains_locomotor] <-
    stringr::str_remove(new_names[contains_locomotor], "group_locomotor_milestones\\.")
  names(df) <- new_names
  df
}

remove_X_meta_cols <- function(df) {
  dplyr::select(df, -contains("X_"), -contains("meta.instanceID"))
}

remove_redundant_group_labels <- function(df) {
  names(df) <- stringr::str_remove_all(names(df), 'group_homevisitquestionnaires\\.')
  names(df) <- stringr::str_remove_all(names(df), 'group_combinedquestionnaires\\.')
  df
}

clean_dfs <- function(df) {
  df %>%
    reconcile_typicalday() %>%
    remove_technology_use_scale() %>%
    remove_doctor_told_you() %>%
    remove_permissive_locomotor_milestones_label() %>%
    remove_databrary_fields() %>%
    remove_X_meta_cols() %>%
    remove_redundant_group_labels()
}
```

Let's test this workflow with the unmodified files.

```{r}
targets::tar_load(df_merge_287_cols_1, store="../_targets")
targets::tar_load(df_merge_287_cols_2, store="../_targets")
targets::tar_load(df_merge_288_cols, store="../_targets")

df1m <- clean_dfs(df_merge_287_cols_1)
dim(df1m)

df2m <- clean_dfs(df_merge_287_cols_2)
dim(df2m)

df3m <- clean_dfs(df_merge_288_cols)
dim(df3m)

(names(df1m) == names(df2m)) |> sum()
(names(df1m) == names(df3m)) |> sum()
```

### Merging files at last {-}

```{r, eval=FALSE}
df <- rbind(df1m, df2m, df3m)
```

::: {.rmdnote}
As of 2022-12-15, the above has now been incorporated into `R/functions.R` and into the `_targets.R` workflow.
:::

## Merge with Databrary info {-}

For each session (row) in the merged data frame, we pull data from the associated Databrary volume and session.
These data are merged with that drawn from KBT.

```
tar_target(
  home_visit_w_databrary_df,
  add_databrary_info_to_home_visit_df(home_visit_df)
)
```

The `add_databrary_info_to_home_visit()` function in `R/functions.R` does most of the work.

## Clean and prepare for export {-}

<!--chapter:end:13-home-visit.Rmd-->

# Data dictionary {-}

<!--chapter:end:14-data-dictionary.Rmd-->

# Post-visit notes {-}

## Select forms from KBT {-}

The post-visit notes are stored in a separate KBT form with "Post-Visit" in the title.

```
tar_target(kb_post_visit, dplyr::filter(
    kb_df, stringr::str_detect(title, "Post\\-Visit")
  ))
```

## Download forms as XLSX {-}

A special function `make_post_visit_df()` downloads the XLSX forms, converts them to CSVs, 
saves the CSVs in a specific directory, and then selects one of them--the most recent form--to open as a data frame.

There is a smaller, older post-visit data file with fewer fields that can be reconciled with the current active one at a later date.

```
tar_target(
    post_visit_df,
    make_post_visit_df(kb_post_visit,
                       "data/xlsx/post_visit",
                       "data/csv/post_visit")
  ),
```


<!--chapter:end:15-post-visit-notes.Rmd-->

# (PART\*) Data Visualization {-} 

<!--chapter:end:20-visualizing.Rmd-->

# Screening visualizations {-}

These visualizations are intended as a way to test the integrity and utility of the data export and cleaning workflow.

## Setup {-}

```{r load-viz-pkgs}
library(targets)
library(tidyverse)
library(forcats)
```

To calculate cumulative screening/recruiting calls by site, we have to add an index variable

```{r load-screening-df, eval=FALSE}
targets::tar_load(screen_df, store="../_targets")
```

```{r}
screen_df <- readr::read_csv(file.path(here::here(), "data/csv/screening/agg/PLAY-screening-2023-06-23.csv"))
```

## Dates & times

To calculate cumulative screening/recruiting calls by site, we have to add an index variable

```{r}
df <- screen_df |>
  dplyr::arrange(submit_date) %>%
  dplyr::mutate(n_calls = seq_along(submit_date))
```

### Calls across time {-}

```{r, fig.cap="Cumulative screening calls by year and site"}
df |>
    dplyr::filter(!is.na(submit_date), !is.na(n_calls), !is.na(site_id)) %>%
    ggplot() +
    aes(submit_date, n_calls, color = site_id) +
    geom_point()
```

```{r fig-screening-calls-cum, fig.cap="Cumulative screening calls by year and site", eval=FALSE}
plot_call_timeseries(df)
```

### Calls by site {-}

```{r fig-screening-calls-by-site, fig.cap="Cumulative screening calls by site"}
calls_by_site_plot <- function(df) {
  df |>
    filter(!is.na(site_id)) %>%
    ggplot() +
    aes(fct_infreq(site_id), fill = site_id) +
    geom_bar() +
    theme(axis.text.x = element_text(
      angle = 90,
      vjust = 0.5,
      hjust = 1
    )) + # Rotate text
    labs(x = "site") +
    theme(legend.position = "none")
}

calls_by_site_plot(df)
```

## Demographics {-}

### Child age {-}

Child age in months (`child_age_mos`) by `child_sex`.

```{r fig-age-hist-screening, fig.cap="Histogram of child age at time of recruiting call."}
screen_df |>
  dplyr::filter(!is.na(child_age_mos),!is.na(child_sex)) |>
  ggplot() +
  aes(child_age_mos, fill = child_sex) +
  geom_histogram(bins = 50)
```

::: {.rmdnote}

Some of the code to clean the `screen_df` variables could be incorporated into an earlier stage of the workflow.

:::

## Language

### To child {-}

Language(s) spoken to child by `child_sex`.

```{r xtabs-language-by-sex}
df <- screen_df |>
  dplyr::mutate(language_spoken_child = stringr::str_replace_all(language_spoken_child, " ", "_"),
                language_spoken_home = stringr::str_replace_all(language_spoken_home, " ", "_"))
xtabs(formula = ~ child_sex + language_spoken_child,
      data = df)
```

### At home {-}

```{r xtabs-language-at-home-by-sex}
xtabs(formula = ~ child_sex + language_spoken_home, data = df)
```

### To child vs. at home {-}

```{r xtabs-language-child-vs-home}
xtabs(formula = ~ language_spoken_child + language_spoken_home, data = df)
```
## Child health

### Child born on due date {-}

```{r xtabs-duedate}
xtabs(formula = ~ child_sex + child_bornonduedate,
      data = screen_df)
```

::: {.rmdnote}

There are a large number of NAs. Cross-check with the earlier version 
of the survey. It's possible that this question was not asked early-on.

:::

### Child weight {-}

Must convert pounds and ounces to decimal pounds.

```{r fig-birthwt-hist}
df <- screen_df %>%
  dplyr::mutate(.,
                birth_weight_lbs = child_weight_pounds + child_weight_ounces/16)

df |>
  dplyr::filter(!is.na(birth_weight_lbs), !is.na(child_sex)) |>
  dplyr::filter(birth_weight_lbs > 0) |>
  ggplot() +
  aes(x = birth_weight_lbs, fill = child_sex) +
  geom_histogram(binwidth = 0.33) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

### Birth complications {-}

```{r xtabs-birth-compl}
xtabs(formula = ~ child_sex + child_birth_complications,
      data = screen_df)
```
```{r table-birth-compl}
screen_df |>
  dplyr::filter(!is.na(child_birth_complications_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_birth_complications_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Major illnesses or injuries {-}

```{r xtabs-illness-injuries}
xtabs(formula = ~ child_sex + child_major_illnesses_injuries,
      data = screen_df)
```
```{r table-illness-injuries}
screen_df |>
  dplyr::filter(!is.na(child_illnesses_injuries_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_illnesses_injuries_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child vision

```{r xtabs-vision}
xtabs(formula = ~ child_sex + child_vision_disabilities,
      data = screen_df)
```

```{r table-vision}
screen_df |>
  dplyr::filter(!is.na(child_vision_disabilities_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_vision_disabilities_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child hearing

```{r xtabs-hearing}
xtabs(formula = ~ child_sex + child_hearing_disabilities,
      data = screen_df)
```

```{r table-hearing}
screen_df |>
  dplyr::filter(!is.na(child_hearing_disabilities_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_hearing_disabilities_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child developmental delays

```{r xtabs-dev-delays}
xtabs(formula = ~ child_sex + child_developmentaldelays,
      data = screen_df)
```

```{r table-dev-delays}
screen_df |>
  dplyr::filter(!is.na(child_developmentaldelays_specify)) |>
  dplyr::select(child_age_mos, child_sex, child_developmentaldelays_specify) |>
  dplyr::arrange(child_age_mos) |>
  knitr::kable(format = 'html')
```

### Child sleep {-}

::: {.rmdimportant}

This is work yet-to-be-done. The time stamps need to be reformatted prior to
visualization.

:::

#### Bed time {-}

```{r fig-bed-time-hist}
extract_sleep_hr <- function(t) {
  t |>
    stringr::str_extract("^[0-9]{2}\\:[0-9]{2}\\:[0-9]{2}") |>
    hms::as_hms()
}

df <- screen_df |>
  dplyr::mutate(child_sleep_time = extract_sleep_hr(child_sleep_time)) |>
  dplyr::filter(!is.na(child_sleep_time)) 

df |>
  dplyr::filter(!is.na(child_sleep_time),
                !is.na(child_sex)) |>
  ggplot() +
  aes(child_sleep_time, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

Some of the bed times are probably not in correct 24 hr time.

```{r table-bed-time}
df |>
  dplyr::filter(child_sleep_time < hms::as_hms("16:00:00")) |>
  dplyr::select(site_id, subject_number, child_sleep_time) |>
  dplyr::arrange(site_id, subject_number) |>
  knitr::kable('html')
```

#### Wake time {-}

```{r fig-wake-time-hist}
df <- screen_df |>
  dplyr::mutate(child_wake_time = extract_sleep_hr(child_wake_time)) |>
  dplyr::filter(!is.na(child_wake_time)) 

df |>
  dplyr::filter(!is.na(child_wake_time),
                !is.na(child_sex)) |>
  ggplot() +
  aes(child_wake_time, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

There are some unusual wake times, too.

```{r table-wake-time}
df |>
  dplyr::filter(child_wake_time > hms::as_hms("16:00:00")) |>
  dplyr::select(site_id, subject_number, child_wake_time) |>
  dplyr::arrange(site_id, subject_number) |>
  knitr::kable('html')
```

#### Sleep duration {-}

```{r fig-sleep-dur-hist}
df <- screen_df |>
  dplyr::mutate(child_sleep_time = extract_sleep_hr(child_sleep_time),
                  child_wake_time = extract_sleep_hr(child_wake_time)) |>
  dplyr::filter(!is.na(child_sleep_time),
                !is.na(child_wake_time)) |>
  dplyr::mutate(child_sleep_secs = (child_sleep_time - child_wake_time))

df |>
  dplyr::filter(!is.na(child_sleep_secs)) |>
  ggplot() +
  aes(child_sleep_secs, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```
Again, there are some unusual values.

```{r table-sleep-dur}
df |>
  dplyr::filter(child_sleep_secs < 12000) |>
  dplyr::select(site_id, subject_number, child_sleep_time, child_wake_time, child_sleep_secs) |>
  dplyr::arrange(site_id, subject_number) |>
  knitr::kable('html')
```


#### Nap hours {-}

```{r fig-nap-hrs-hist}
df <- screen_df |>
  dplyr::mutate(child_nap_hours = as.numeric(child_nap_hours)) |>
  dplyr::filter(!is.na(child_sleep_time)) 

df |>
  dplyr::filter(!is.na(child_nap_hours),
                !is.na(child_sex)) |>
  ggplot() +
  aes(child_nap_hours, fill = child_sex) +
  geom_histogram(bins = 18) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```
And there are some very long nappers or null values we need to capture.

```{r table-nap-hrs}
df |>
  dplyr::filter(child_nap_hours > 5) |>
  dplyr::select(site_id, subject_number, child_nap_hours) |>
  dplyr::arrange(site_id, subject_number) |>
  knitr::kable('html')
```


#### Sleep location {-}

```{r, eval=FALSE}
xtabs(formula = ~ child_sex + child_sleep_location,
      data = screen_df)
```


## Mother {-}

### Biological or adoptive {-}

```{r xtabs-mom-bio}
xtabs(formula = ~ child_sex + mom_bio,
      data = screen_df)
```
### Age at childbirth {-}

```{r fig-mom-age-childbirth}
screen_df |>
  dplyr::filter(!is.na(mom_childbirth_age), !is.na(child_sex)) |>
  ggplot() +
  aes(x = mom_childbirth_age, fill = child_sex) +
  geom_histogram(bins = 25) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

Clearly, there are some impossible (erroneous) maternal ages > 100. Here are details:

```{r table-mom-childbirth}
old_moms <- screen_df |>
  dplyr::filter(mom_childbirth_age > 55)

old_moms |>
  dplyr::select(submit_date, site_id, subject_number, mom_childbirth_age) |>
  knitr::kable(format = 'html')
```

### Birth country {-}

```{r xtabs-mom-birth-country}
df <- screen_df |>
  dplyr::mutate(mom_birth_country = dplyr::recode(
    mom_birth_country, 
    unitedstates = "US",
    united_states = "US",
    othercountry = "Other",
    other_country = "Other",
    refused = "Refused"
  ))

xtabs(~ mom_birth_country, data = df)
```

```{r table-mom-birth-country-non-us}
df <- screen_df |>
  dplyr::mutate(mom_birth_country_specify = stringr::str_to_title(mom_birth_country_specify)) |>
  dplyr::filter(!is.na(mom_birth_country_specify)) |>
  dplyr::select(child_sex, mom_birth_country_specify)

unique(df$mom_birth_country_specify)
```

### Education

```{r xtabs-mom-educ}
df <- screen_df |>
  dplyr::filter(!is.na(mom_education)) |>
  dplyr::select(child_sex, mom_education)

xtabs(~ mom_education, data = df)
```
::: {.rmdnote}

This requires some recoding work.

:::

### Employment

```{r xtabs-mom-employ}
df <- screen_df |>
  dplyr::filter(!is.na(mom_employment))

xtabs(~ mom_employment, data = df)
```

### Occupation

This information is available, but would need to be substantially recoded to be useful in summary form.

### Jobs number

```{r xtabs-mom-jobs-number}
df <- screen_df |>
  dplyr::filter(!is.na(mom_jobs_number))

xtabs(~ mom_jobs_number, data = df)
```

```{r xtabs-mom-jobs-vs-employ}
df <- screen_df |>
  dplyr::filter(!is.na(mom_jobs_number),
                !is.na(mom_employment))

xtabs(~ mom_jobs_number + mom_employment, data = df)
```
### Race and ethnicity {-}

```{r xtabs-race-ethnicity}
# df <- screen_df %>%
#   dplyr::mutate(
#     .,
#     mom_race = dplyr::recode(
#       mom_race,
#       morethanone = "more_than_one",
#       americanindian = "american_indian"
#     ),
#     mother_ethnicity = dplyr::recode(
#       mother_ethnicity,
#       hispanic_or_la = "hispanic",
#       not_hispanic_o = "not_hispanic",
#       nothispanic = "not_hispanic"
#     )
#   )
# xtabs(formula = ~ mother_race + mother_ethnicity,
#       data = df)
```

## Childcare

### Types

```{r xtabs-childcare-types}
df <- screen_df |>
  dplyr::filter(!is.na(childcare_types))
                
xtabs(~ childcare_types, data = df)
```
::: {.rmdnote}

This requires some cleaning.

:::

### Hours

```{r childcare-hrs}
df <- screen_df |>
  dplyr::filter(!is.na(childcare_hours)) |>
  dplyr::arrange(childcare_hours)

unique(df$childcare_hours)
```
::: {.rmdnote}

This requires some cleaning.

:::

### Language

```{r child-care-language}
df <- screen_df |>
  dplyr::filter(!is.na(childcare_language))

unique(df$childcare_language)
```
::: {.rmdnote}

This requires some cleaning.

:::

<!--chapter:end:21-viz-screening.Rmd-->

# Home visit visualizations {-}

## Load home visit data {-}

```{r load-home-visit-df}
targets::tar_load(home_visit_df, store="../_targets")
```

### Demographics {-}

#### Child age {-}

Child age in months (`age_group`) by `child_sex`.

Note: The child's exact age in months is part of the Databrary-related data. 
That is on the work plan.

```{r fig-age-grp-by-sex, fig.cap="Participants by age group and sex"}
home_visit_df %>%
  dplyr::filter(.,!is.na(age_group),!is.na(child_sex)) %>%
  ggplot() +
  aes(age_group, fill = child_sex) +
  geom_bar() +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

### Language exposure {-}

```{r clean-lang-df}
df <- home_visit_df %>%
  dplyr::mutate(., language_child = stringr::str_replace_all(language_child, " ", "_"))
xtabs(formula = ~ child_sex + language_child, data = df)
```

### Locomotor milestones {-}

```{r make-loco-df}
play_loco <- home_visit_df %>%
  dplyr::select(
    .,
    age_group,
    child_sex,
    language_child,
    site_id,
    subject_number,
    locomotor_milestones.who_walk.who_walk_onset_mo,
    locomotor_milestones.k_walk.k_walk_onset_mo,
    locomotor_milestones.crawl_onset.crawl_onset_mo
  ) %>%
  dplyr::rename(
    .,
    walk_mos_who = locomotor_milestones.who_walk.who_walk_onset_mo,
    walk_mos_kea = locomotor_milestones.k_walk.k_walk_onset_mo,
    crawl_mos = locomotor_milestones.crawl_onset.crawl_onset_mo
  ) %>%
  dplyr::mutate(
    .,
    walk_mos_who = as.numeric(walk_mos_who),
    walk_mos_kea = as.numeric(walk_mos_kea),
    crawl_mos = as.numeric(crawl_mos)
  )
```

#### Check for anomalous values {-}

```{r}
crawl_mos_min <- 4
walk_mos_min <- 6
```


##### Anomalous crawling onset {-}

```{r}
play_loco %>%
  dplyr::select(., site_id, subject_number, crawl_mos) %>%
  dplyr::filter(., crawl_mos < crawl_mos_min) %>%
  knitr::kable(format = 'html') 
```

##### Anomalous walking onset (KEA criteria) {-}

```{r}
play_loco %>%
  dplyr::select(., site_id, subject_number, walk_mos_kea) %>%
  dplyr::filter(., walk_mos_kea < walk_mos_min) %>%
  knitr::kable(format = 'html') 
```

##### Anomalous walking onset (WHO criteria) {-}

```{r}
play_loco %>%
  dplyr::select(., site_id, subject_number, walk_mos_who) %>%
  dplyr::filter(., walk_mos_who < walk_mos_min) %>%
  knitr::kable(format = 'html') 
```

#### Crawl onset {-}

```{r fig-crawl-onset-hist, fig.cap="Age of crawling onset (mos) by sex"}
play_loco %>%
  dplyr::filter(., crawl_mos > crawl_mos_min, !is.na(crawl_mos)) %>%
  ggplot(.) +
  aes(crawl_mos, fill = child_sex) +
  geom_histogram(bins = 12) +
  theme(legend.position = "bottom") +
  theme(legend.title = element_blank())
```

#### Walk onset {-}

```{r fig-walk-mos-kea, fig.cap="Age (mos) of walking onset (KEA criteria) by sex"}
play_loco %>%
  dplyr::filter(., walk_mos_kea > walk_mos_min, !is.na(walk_mos_kea)) %>%
  ggplot(.) +
  aes(walk_mos_kea, fill = child_sex) +
  theme(legend.position="bottom") +
  geom_histogram(bins = 10)
```

```{r fig-walk-mos-who, fig.cap="Age (mos) of walking onset (WHO criteria) by sex"}
play_loco %>%
  dplyr::filter(., walk_mos_who > walk_mos_min, !is.na(walk_mos_who)) %>%
  ggplot(.) +
  aes(walk_mos_who, fill = child_sex) +
  geom_histogram(bins=12) +
  theme(legend.position="bottom") +
  theme(legend.title = element_blank())
```

```{r fig-walk-mos-kea-who, fig.cap="Walking onset by WHO vs. KEA criteria"}
play_loco %>%
  dplyr::filter(., walk_mos_who > walk_mos_min, !is.na(walk_mos_who), walk_mos_kea > walk_mos_min, !is.na(walk_mos_kea)) %>%
  ggplot(.) +
  aes(walk_mos_who, walk_mos_kea, color = child_sex) +
  geom_point() +
  geom_smooth(method = "lm") +
  xlim(8, 18) +
  ylim(8, 18) +
  theme(legend.position = "bottom") +
  theme(aspect.ratio = 1) +
  theme(legend.title = element_blank()) -> walk_p

ggExtra::ggMarginal(
  walk_p,
  play_loco,
  walk_mos_who,
  walk_mos_kea,
  type = "density",
  margins = "both",
  groupColour = TRUE,
  groupFill = TRUE
)
```

```{r fig-walk-mos-kea-crawl-mos, fig.cap="Walking onset vs. Crawling"}
play_loco %>%
  dplyr::filter(., crawl_mos > crawl_mos_min, !is.na(crawl_mos), walk_mos_kea > walk_mos_min, !is.na(walk_mos_kea)) %>%
  ggplot(.) +
  aes(crawl_mos, walk_mos_kea, color = child_sex) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme(legend.position = "bottom") +
  theme(aspect.ratio = 1) +
  theme(legend.title = element_blank()) -> walk_p

ggExtra::ggMarginal(
  walk_p,
  play_loco,
  walk_mos_who,
  walk_mos_kea,
  type = "density",
  margins = "both",
  groupColour = TRUE,
  groupFill = TRUE
)
```

### Health {-}

#### Feeding {-}

```{r make-feeding-df}
feeding <- home_visit_df %>%
  dplyr::select(
    .,
    age_group,
    child_sex,
    site_id,
    subject_number,
    language_child,
    health.feeding_nutrition.breastfeed,
    health.feeding_nutrition.solidfood_age
  ) %>%
  dplyr::rename(., breastfeed = health.feeding_nutrition.breastfeed,
                solid_food_mos = health.feeding_nutrition.solidfood_age) %>%
  dplyr::mutate(., solid_food_mos = as.numeric(solid_food_mos))
```

```{r}
xtabs(formula = ~ child_sex + breastfeed, data = feeding)
```

```{r fig-solid-food-mos, fig.cap="Age at introduction of solid foods"}
feeding %>%
  ggplot(.) +
  aes(x = solid_food_mos, color = child_sex, fill = child_sex) +
  geom_histogram(bins = 15) +
  theme(legend.title = element_blank())
```

Clearly, there are some impossible values here.

```{r anomalous-feeding}
feeding |>
  dplyr::select(site_id, subject_number, solid_food_mos) %>%
  dplyr::filter(., solid_food_mos > 12) %>%
  knitr::kable(format = 'html')
```

#### Smoking/drinking {-}

```{r xtabs-smoking-drinking}
smoking_drinking <- home_visit_df %>%
  dplyr::select(
    .,
    age_group,
    child_sex,
    language_child,
    health.smoking.pregnant_smoking,
    health.drinking.pregnant_drinking
  ) %>%
  dplyr::rename(., preg_smoking = health.smoking.pregnant_smoking,
                preg_drinking = health.drinking.pregnant_drinking)

xtabs(formula = ~ preg_smoking + preg_drinking, smoking_drinking)
```

#### Sleeping position {-}

```{r xtabs-sleeping}
sleeping_pos <- home_visit_df %>%
  dplyr::select(
    .,
    age_group,
    child_sex,
    language_child,
    health.general_health.child_sleeping_position
  ) %>%
  dplyr::rename(., child_sleeping_position = health.general_health.child_sleeping_position)

xtabs(formula = ~ child_sleeping_position, data = sleeping_pos)
```

## Post-visit data {-}

We load the post-visit survey data.

```{r load-post-visit-df}
tar_load(post_visit_df, store="../_targets")

dim(post_visit_df)
```

::: {.rmdnote}

Cleaning this data is set aside for future work.

:::

<!--chapter:end:22-viz-home-visit.Rmd-->

# (PART\*) Project Monitoring {-} 

<!--chapter:end:30-management.Rmd-->

# State of PLAY {-}

```{r load-packages}
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(lubridate))
suppressPackageStartupMessages(library(forcats))
```

The following summarizes the current state of the project as of `r (now <- ymd(Sys.Date()))`.

## Recent data {-}

```{r load-df-targets}
targets::tar_load(screen_df, store="../_targets")
targets::tar_load(home_visit_df, store="../_targets")
```

### Last two weeks {-}

#### Screening calls {-}

```{r fig-last-2-wk-calls}
two_weeks_ago <- now - dweeks(2)
screen_last_two_weeks_df <- screen_df %>%
  dplyr::filter(submit_date > two_weeks_ago)
```

There have been $n=$ `r dim(screen_last_two_weeks_df)[1]` recruiting calls since `r two_weeks_ago`.

```{r, fig.cap="Screening calls in last 2 weeks by site"}
calls_by_site_plot(screen_last_two_weeks_df)
```

#### Home visits {-}

```{r home-visit-stats-last-2-wks}
home_last_two_weeks_df <- home_visit_df %>%
   dplyr::filter(date_today > two_weeks_ago)
```

There have been $n=$ `r dim(home_last_two_weeks_df)[1]` home visits since `r two_weeks_ago`.

```{r fig-last-2-wk-home-visit, fig.cap="Home visits in last 2 weeks by site"}
calls_by_site_plot(home_last_two_weeks_df)
```

### Last month {-}

#### Screening calls {-}

```{r fig-last-mo-calls}
month_ago <- now - dmonths(1)
screen_last_month_df <- screen_df %>%
  dplyr::filter(submit_date > month_ago)
```

There have been $n=$ `r dim(screen_last_month_df)[1]` recruiting calls since `r month_ago`.

```{r, fig.cap="Screening calls in last month by site"}
calls_by_site_plot(screen_last_month_df)
```

#### Home visits {-}

```{r home-visit-stats}
home_last_month_df <- home_visit_df %>%
   dplyr::filter(date_today > month_ago)
```

There have been $n=$ `r dim(home_last_month_df)[1]` home visits since `r month_ago`.

```{r fig-last-mo-home-visit, fig.cap="Home visits in last month by site"}
calls_by_site_plot(home_last_month_df)
```

### Last 3 mos {-}

#### Screening calls {-}

```{r}
three_mos_ago <- now - dmonths(3)
screen_last_3_df <- screen_df |>
   dplyr::filter(submit_date > three_mos_ago)
```

There have been $n=$ `r dim(screen_last_3_df)[1]` screening calls since `r three_mos_ago`. 

```{r fig-last-3mo-calls, fig.cap="Screening calls in last 3 months by site"}
calls_by_site_plot(screen_last_3_df)
```

#### Home visits {-}

```{r home-3mos-visit-stats}
home_last_3_month_df <- home_visit_df %>%
   dplyr::filter(date_today > three_mos_ago)
```

There have been $n=$ `r dim(home_last_3_month_df)[1]` home visits since `r three_mos_ago`.

```{r fig-last-3mo-home-visit, fig.cap="Home visits in last 3 months by site"}
calls_by_site_plot(home_last_3_month_df)
```

### Last 6 mos {-}

#### Screening calls {-}

```{r}
six_mos_ago <- now - dmonths(6)
screen_last_6_df <- screen_df |>
   dplyr::filter(submit_date > six_mos_ago)
```

There have been $n=$ `r dim(screen_last_6_df)[1]` screening calls since `r six_mos_ago`.

```{r fig-last-6mo-calls, fig.cap="Screening calls in last 6 months by site"}
calls_by_site_plot(screen_last_6_df)
```

#### Home visits {-}

```{r home-6mos-visit-stats}
home_last_6_month_df <- home_visit_df %>%
   dplyr::filter(date_today > six_mos_ago)
```

There have been $n=$ `r dim(home_last_6_month_df)[1]` home visits since `r six_mos_ago`.

```{r fig-last-6mo-home-visit, fig.cap="Home visits in last 6 months by site"}
calls_by_site_plot(home_last_6_month_df)
```

## Overall {-}

### From Databrary {-}

Because of some minor anomalies merging the older KBT surveys, we query the Databrary API for the most complete data about PLAY sessions.
For debugging purposes, we set `vb = TRUE` so we get complete information about what's working and what is not.

```{r get-session-status-from-databrary, message=FALSE, warning=FALSE}
databraryapi::login_db(Sys.getenv("DATABRARY_LOGIN"))
databrary_df <- purrr::map_df(play_vols$play_site_id, make_site_session_summary, vb = TRUE) 

databrary_df %>%
  dplyr::select(., site_name, site_id, site_vol_id, PLAY_Gold, PLAY_Silver, No_Visit, `NA`) %>%
  dplyr::arrange(., desc(PLAY_Gold)) %>%
  knitr::kable(., format = 'html') 
```

### From KBT {-}

```{r load-home-visit-dataframe}
targets::tar_load(home_visit_w_databrary_df, store="../_targets")

gold_silver <- home_visit_w_databrary_df %>%
  dplyr::filter(!is.na(group_name))

xtabs(~ group_name + age_group, gold_silver)
```

```{r}
xtabs(~ group_name + child_sex, gold_silver)
```

```{r}
df_race_eth <- gold_silver %>%
  dplyr::filter(!is.na(group_name)) %>%
  dplyr::mutate(., participant_race = recode(participant_race, 
                                             `Black or African American` = "Black_or_African_American",
                                             `More than one` = "More_than_one"),
                participant_ethnicity = recode(participant_ethnicity, 
                                               `Hispanic or Latino` = "Hispanic_or_Latino",
                                               `Not Hispanic or Latino` = "Not_Hispanic_or_Latino"))

xtabs(~ participant_race + participant_ethnicity, df_race_eth)
```
### By site, location, & QA status {-}

```{r xtabs-site-qa-status}
xtabs(~ site_id + group_name, gold_silver)
```

```{r fig-qa-level-by-state, fig.cap="QA level by State"}
gold_silver %>%
    ggplot(.) +
    aes(forcats::fct_infreq(context_state), fill = context_state) +
    geom_bar() +
    facet_grid(. ~ group_name) +
    theme(axis.text.x = element_text(
      angle = 90,
      vjust = 0.5,
      hjust = 1
    )) + # Rotate text
    labs(x = "State", y = "N participants") +
    theme(legend.position = "none")
```

## Clean-up {-}

```{r clean-up}
unlink("../.databrary.RData", recursive = TRUE)
databraryapi::logout_db()
```

<!--chapter:end:32-state-of-PLAY.Rmd-->

