# Screening call {-}

## Collection protocol {-}

Details about the data collection [protocol for participant screening and recruiting](https://www.play-project.org/collection.html#Participant_Recruitment) can be found on the [PLAY Project website](https://play-project.org).

## Approach

To make the workflow more robust and reproducible, much of the work is embedded in functions and extensive use is made of the [`{targets}`](https://cran.r-project.org/web/packages/targets/) package. 
This document describes the workflow, but none of these code chunks are executed.

We leave execution to the `targets::tar_make()` function which updates components as needed.

:::{.rmdnote}
I am currently working on implementing most of the functions using the `box` package. This allows better isolation of dependencies within different components of the workflow.

The box-related functions are in a new `play/` directory, and the R source files are divided into categories.
The functions related to processing the screening/demographic data are in `play/screen.R`.

They will be loaded into the workspace via `box::use(play/screen)` or for modules within `play/` via `box::use(./screen)`.
:::

## Retrieve data about all files from KoBoToolbox (KBT) {-}

We maintain a list of data files available on KBT in a data frame called `kb_df`.

```
tar_target(kb_df, list_kobo_data())
```

Note: The new 'box'-ized function for this will be `kobo$list_data()`.

::: {.rmdnote}
We can control how often we query the KBT server to download and update the data files.
There are variables in the header of the `_targets.R` called `update_interval` and `interval_units` we use to control this.
Right now, it is set at 2 days.
:::

### Save selected raw files to local directory {-}

A function `make_screening_df()`, downloads the XLSX files, converts them to CSVs, copies the CSVs to a specified target directory, then opens the CSVs and combines them into a single data frame stored as `screen_df`.

```
tar_target(
  screen_df,
    make_screening_df(kb_screen, "data/xlsx/screening", "data/csv/screening"),
    cue = tarchetypes::tar_cue_age(
      name = demog_submissions,
      age = as.difftime(update_interval, units = update_interval_units)
    )
)
```

Note: The 'box'-ized function for this will be `screen$make_df()`.

## Clean files

There are three screening/demographic data files. Each one represents a slightly different version of the questionnaire.

```{r list-screening-csvs}
list.files('data/csv/screening')
```

The file beginning with '275882' is the oldest file. It contains the original questions asked of English-speaking parents.
The file beginning with '334134' contains questions asked of Spanish-speaking families.
The file beginning with '359546' contains questions asked of English-speaking families in the newer iteration of the questionnaire.
The latter two files, '334134' and '359546' are more similar to one another, but the variable names are *not* identical.
As a result, we need slightly different cleaning and renaming procedures for each file.

### Approach

For each file, we need to achieve the following:

#### Rename field names

Here are the field names for the older ('275882') file:

```{r}
s1n <- readr::read_csv("../data/csv/screening/275882_PLAY_Demographic_Questionnaire.csv", show_col_types = FALSE) |>
  names()

head(s1n)
```
It shows that some of the questions contain metadata about the question group.

Here are similar field name lists for the other two:

```{r}
s2n <- readr::read_csv("../data/csv/screening/334134_PLAY_Demographic_Questionnaire_Spanish.csv", show_col_types = FALSE) |>
  names()

head(s2n)
```

```{r}
s3n <- readr::read_csv("../data/csv/screening/359546_PLAY_Demographic_Questionnaire.csv", show_col_types = FALSE) |>
  names()

head(s3n)
```

#### Use address information to map to a participants' county for later geographic-related analyses.

We make use of the `tidycensus` package to pull a participant's State and County FIPS codes. 
The Census API can also give us tract, and block group information, but there are privacy concerns with
reporting data at increasingly fine levels of resolution.
We do not have permission from participants to report, for example, their 
Census block group.

The `play/geo` module contains functions to support geographic data operations.

#### Remove identifying information

We need address information for the geographic data processing, but we must remove it early-on in the process.

```{r}
detect_str_in_name <- function(name_str, detect_str) {
  name_str[stringr::str_detect(name_str, detect_str)]
} 
```

The raw data files contain names:

```{r}
detect_str_in_name(s1n, "name")
```

```{r}
detect_str_in_name(s2n, "name")
```

```{r}
detect_str_in_name(s3n, "name")
```

This includes the participant contact information needed for the prior step,
but also participant phone, email information, and the names of the 

The files contain phone numbers:

```{r}
detect_str_in_name(s1n, "phone") |> head()
```

```{r}
detect_str_in_name(s2n, "phone") |> head()
```

```{r}
detect_str_in_name(s3n, "phone") |> head()
```

The files contain email addresses:

```{r}
detect_str_in_name(s1n, "email")
```

And as we know from the section about the Census-related data, the files contain address information:

```{r}
detect_str_in_name(s1n, "address")
```
```{r}
detect_str_in_name(s1n, "address")
```

```{r}
detect_str_in_name(s2n, "address")
```

```{r}
detect_str_in_name(s3n, "address")
```

There are also a number of data fields that are largely for administrative purposes.
These often have 'note', 'acknowledge', or 'endscreener' in the field name.

```{r}
detect_str_in_name(s1n, "note|acknowledge|endscreener")
```

```{r}
detect_str_in_name(s2n, "note|acknowledge|endscreener")
```

```{r}
detect_str_in_name(s3n, "note|acknowledge|endscreener")
```

#### Create a merged data frame

Not all of the data files have the same fields.

For example:

```{r}
detect_str_in_name(s1n, "race")
```

```{r}
detect_str_in_name(s2n, "race")
```
```{r}
detect_str_in_name(s3n, "race")
```
#### Create a data dictionary

### Working notes

Create a "clean" working data frame for the first (of 3) screening files.

```{r}
box::use(readr[read_csv])
box::use(.. / play / geo)
box::use(.. / play / screen)

fl <- list.files("../data/csv/screening/", full.names = TRUE)

# helper function
test_clean_1 <- function(fn) {
  df <- readr::read_csv(fn, show_col_types = FALSE)
  df |>
    screen$remove_variable_headers() |>
    geo$make_addresses("new") |>
    geo$get_multiple_census_geos() |>
    screen$remove_variable_identifiers() |>
    screen$remove_metadata_fields() |>
    screen$remove_databrary_fields()
}

d1c <- test_clean_1(fl[1])
```
Create similar data frames for the 2nd and 3rd screening files.

```{r}
d2c <- test_clean_1(fl[2])
d3c <- test_clean_1(fl[3])
```

Check the first 15 variables.

```{r}
head(names(d1c), 15)
```

```{r}
head(names(d2c), 15)
```

```{r}
head(names(d3c), 15)
```

