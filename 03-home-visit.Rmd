# Home visit {-}

## Protocol {-}

Details about the data collection protocol for the home visit can be found on the [PLAY Project website]((https://www.play-project.org/collection.html#Home_Visit).

## Download data {-}

Data files for each of the language by age-group conditions are stored on KoBoToolbox (KBT).

Store all of the data files on KBT in `kb_df`.

```
tar_target(kb_df, list_kobo_data()),
```

```{r home-visit-list-forms}
library(targets)
targets::tar_load(kb_df)
kb_df
```

List data forms specific to the home visit by filtering the files with names that contain "Home".

```
tar_target(kb_home, dplyr::filter(kb_df, stringr::str_detect(title, "Home")))
```

```{r home-visit}
targets::tar_load(kb_home)
kb_home
```

### Save selected raw files to local directory {-}

Prepare to retrieve all home visit files.

```{r}
n_files <- dim(kb_home)[1]
```

There are $n=$ `r n_files` home visit data files.

```
tar_target(home_visit_dir_xlsx, "data/xlsx/home_visit"),
tar_target(home_visit_dir_csv, "data/csv/home_visit"),
tar_target(home_visit_downloads, retrieve_kobo_xlsx(kb_home, home_visit_dir_xlsx))
```

### Normalize file names {-}

Some of the form names are inconsistent, so we normalize them to fit the following pattern:

`<form_id>_PLAY_HomeQuestionnaires_<age_group>_<lang_group>.xlsx`

```
tar_target(home_visit_renamed, rename_home_xlsx(home_visit_dir_xlsx, home_visit_dir_xlsx))
```

### Save xlsx as csv {-}

```
tar_target(home_visit_xlsx_to_csv, load_xlsx_save_many_csvs(home_visit_dir_xlsx, home_visit_dir_csv, "Home"))
```

### Split MB-CDI from other questions {-}

Next we import a CSV for a given form year, age group, and language group, and create two new CSV files: one with the MB-CDI data and one with all of the other survey questions.

By default, the document presumes that we want to convert **all** of the CSV files

Extract the 'non-mbcdi' questions first and add 'non_mbcdi' to the filename.

```
tar_target(home_visit_csvs, list.files(home_visit_dir_csv, '^[0-9]+_PLAY.*\\csv', full.names = TRUE))

tar_target(home_visit_non_mbcdi, purrr::map(
    home_visit_csvs,
    open_split_save,
    csv_save_dir = home_visit_dir_csv,
    these_questions = 'non_mbcdi'
  ))
```

Extracting the MB-CDI data has nearly the same function call, but the `these_questions` parameter is set to 'mbcdi'.

```
tar_target(home_visit_mbcdi, purrr::map(
    home_visit_csvs,
    open_split_save,
    csv_save_dir = home_visit_dir_csv,
    these_questions = 'mbcdi'
  ))
```

## Clean data {-}

### Remove identifiers {-}

The function `remove_identifiers()` in `R/kobo_export` detects the presence of names, addresses, phone numbers, email, and dates in the field names for an input file and removes these fields.
It also modifies the file name by appending `_deidentified`.

The `remove_identifiers()` function detects these fields:

```{r}
source("~/rrr/KoBoToolbox/R/functions.R", echo = FALSE, print.eval = FALSE)
remove_identifiers
```

The **non-MBCDI file** contains the identifiers, so that is the target of this removal process.

::: {.rmdnote}
Note that we have added `data` to `.gitignore` in `protocol/`, the root directory for the HTML protocol, so *none* of the data files should be made available via git or GitHub. This also means that there is **no version control** being done on raw data files themselves.
:::

```
tar_target(home_visit_non_mbcdi_csvs, list.files(home_visit_dir_csv, '^[0-9]+_non_mbcdi.*\\csv', full.names = TRUE)),

tar_target(home_visit_remove_identifiers, purrr::map(
    home_visit_non_mbcdi_csvs,
    open_deidentify_save,
    csv_save_dir = home_visit_dir_csv,
    these_questions = 'non_mbcdi'
  ))
```

## Quality assurance (QA) reviews {-}

### MB-CDI files {-}

### Non-MB-CDI files {-}

Create a helper function to create a data set with summary information about the data files.

```{r define-qa-helper}
summarize_non_mbcdi_qs <- function(fn) {
  stopifnot(is.character(fn))
  
  if (!file.exists(fn)) {
    stop('File not found `', fn, '`')
  } else {
    df <- readr::read_csv(fn, show_col_types = FALSE)
    if (!is.data.frame(df)) {
      stop('Error reading data frame')
    } else {
      out_df <- tibble(file_name = basename(fn), n_rows = dim(df)[1], n_vars = dim(df)[2])
      dplyr::arrange(out_df, file_name)
    }
  }
}
```

Select the de-identified CSVs to examine.

```{r generate-qa-report}
targets::tar_load(home_visit_dir_csv)
fl <-
  list.files(
    file.path(home_visit_dir_csv),
    '^[0-9]+_non_mbcdi_[12|18|24].*deidentified',
    full.names = TRUE
  )

PLAY_forms <- purrr::map_df(fl, summarize_non_mbcdi_qs)

PLAY_forms %>%
  knitr::kable(., format = 'html') %>%
  kableExtra::kable_classic()
```

The later forms (with higher form numbers--the leading integers in the file names) are the newer ones.
These generally have the largest number of entries and have similar numbers of columns--either 287 or 288.
Accordingly, we focus our cleaning efforts here first.

We start with the data files that have $n=288$ columns.

```{r}
df740623 <- readr::read_csv("data/csv/home_visit/740623_non_mbcdi_12_bilingual_english_deidentified.csv", show_col_types = FALSE)

df740624 <- readr::read_csv("data/csv/home_visit/740624_non_mbcdi_12_bilingual_spanish_deidentified.csv", show_col_types = FALSE)

sum(names(df740623) == names(df740624))
```

```{r}
df740625 <- readr::read_csv("data/csv/home_visit/740625_non_mbcdi_12_english_deidentified.csv", show_col_types = FALSE)

sum(names(df740623) == names(df740625))
```

```{r}
df740628 <- readr::read_csv("data/csv/home_visit/740628_non_mbcdi_18_english_deidentified.csv", show_col_types = FALSE)

sum(names(df740623) == names(df740628))
```

So, four of the most recent data files with $n=288$ columns can be aggregated without modification.

Let's turn to the more recent files with $n=287$ columns.

```{r}
df740626 <- readr::read_csv("data/csv/home_visit/740626_non_mbcdi_18_bilingual_english_deidentified.csv", show_col_types = FALSE)

df740627 <- readr::read_csv("data/csv/home_visit/740627_non_mbcdi_18_bilingual_spanish_deidentified.csv", show_col_types = FALSE)

sum(names(df740626) == names(df740627))
```

Where does the misalignment arise?

```{r}
names(df740626) == names(df740627)
```

The misalignment arises somewhere near column 92.

```{r}
df740629 <- readr::read_csv("data/csv/home_visit/740629_non_mbcdi_24_english_deidentified.csv", show_col_types = FALSE)

sum(names(df740626) == names(df740629))
```

So, `df740626` and `df740629` are aligned and can be merged.

```{r}
df740630 <- readr::read_csv("data/csv/home_visit/740630_non_mbcdi_24_bilingual_spanish_deidentified.csv", show_col_types = FALSE)

sum(names(df740626) == names(df740630))
names(df740626) == names(df740630)
```

These files also fall out of alignment near column 92.

```{r}
df740631 <- readr::read_csv("data/csv/home_visit/740631_non_mbcdi_24_bilingual_english_deidentified.csv", show_col_types = FALSE)

sum(names(df740626) == names(df740631))
names(df740626) == names(df740631)
```

And these files fall out of alignment near column 92.

Let's see if `df740627`, `df740630`, and `df740631` are aligned with one another.

```{r}
sum(names(df740627) == names(df740630))
sum(names(df740627) == names(df740631))
```

Yes, they are. So, these three can be merged. 
We do that first, then address the discrepancies between aggregates.

## Make aggregate files {-}

### non-MB-CDI files with $n=288$ columns

```
tar_target(files_w_288_cols, list.files(home_visit_dir_csv, 
  "2[3458]_non_mbcdi.*_deidentified", full.names = TRUE)),

tar_target(df_merge_288_cols, make_aggregate_data_file(files_with_288_cols))
```

### non-MB-CDI files with $n=287$ columns

```
tar_target(files_w_287_cols_1, 
  list.files(home_visit_dir_csv, "2[69]_non_mbcdi.*_deidentified", full.names = TRUE)),
tar_target(df_merge_287_cols_1, make_aggregate_data_file(files_w_287_cols_1)),

tar_target(files_w_287_cols_2, 
  list.files(home_visit_dir_csv, list.files(home_visit_dir_csv, "(740627|740630|740631)_non.*_deidentified", full.names = TRUE)),
tar_target(df_merge_288_cols_2, make_aggregate_data_file(files_w_287_cols_2))
```

### Examine groups with $n=287$ cols

We focus on the starting column where the column names diverge, column 92.

```{r}
tar_load(df_merge_287_cols_1)
tar_load(df_merge_287_cols_2)
names(df_merge_287_cols_1)[92]
names(df_merge_287_cols_2)[92]
```

There is an erroneous `group_locomotor_milestones.` in the `df_merge_287_cols_2` column name.

A bit of sleuthing determines that this `group_locomotor_milestones.` label is characteristic of columns 92 to 182.

```{r}
names(df_merge_287_cols_2)[92:287] |> stringr::str_detect(pattern = "group_locomotor_milestones")
```

The following should fix this.

```{r}
old_names <- names(df_merge_287_cols_2)
new_names <- old_names
new_names[92:113] <- stringr::str_remove(new_names[92:113], "group_locomotor_milestones\\.")
names(df_merge_287_cols_2) <- new_names
```

```{r}
names(df_merge_287_cols_2) == names(df_merge_287_cols_1)
```

We have a second problem with columns from 114 to 278.

One of the problems has to do with column 114. There is a question ending `doctor_told_you` in `names(df_merge_287_cols_1)` but not in `names(df_merge_287_cols_2)`.

```{r}
names(df_merge_287_cols_1) |> stringr::str_detect(pattern = "doctor_told_you") |> sum()
names(df_merge_287_cols_2) |> stringr::str_detect(pattern = "doctor_told_you") |> sum()
```

Deleting this question would create additional misalignments and further problems.
We cannot proceed without further discussion with our team.

## Merge with Databrary info {-}

## Clean and prepare for export {-}